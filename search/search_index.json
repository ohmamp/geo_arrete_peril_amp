{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Index Analyse et g\u00e9olocalisation des arr\u00eat\u00e9s de p\u00e9rils sur le territoire de la m\u00e9tropole Aix-Marseille Provence. Installation Veuillez suivre les instructions du guide d'installation . Utilisation Lancement du script Dans le terminal WSL (ou l'invite de commande Ubuntu): Les dossier d'entr\u00e9es et de sorties sont configurables dans le fichier scripts/process.sh . conda activate geo-arretes scripts/process.sh Plusieurs scripts sont d\u00e9finis pour faciliter certaines actions : scripts . Planification de t\u00e2ches Le script runner.bat est un exemple de script permettant de lancer le script process.sh (pr\u00e9sent dans le WSL) depuis le Task Scheduler de Windows. Logs Deux types de logs sont disponibles : batch-logs : dans le dossier batch-logs sont stock\u00e9s un court \u00e9tat des lieux de chaque lanc\u00e9 de script. logs : dans le dossier logs sont stock\u00e9s les logs d\u00e9taill\u00e9s de chaque traitement dans le pipeline du script process.sh . Documentation La documentation g\u00e9n\u00e9r\u00e9e \u00e0 partir du code source est disponible \u00e0 l'adresse suivante : https://geo-arretes.github.io/geo-arretes/ . Elle utilise mkdocs et mkdocstrings pour automatiquement g\u00e9n\u00e9rer la documentation \u00e0 partir des docstrings des fonctions et des classes du code source. pip install mkdocs==1.5.3 mkdocstrings==0.23.0 mkdocs-material==9.5.10 Pour pr\u00e9visualiser la documentation localement, il suffit d'utiliser la commande suivante : mkdocs serve La documentation est alors accessible par d\u00e9faut \u00e0 l'adresse suivante : http://127.0.0.1:8000/ Pour d\u00e9ployer la documentation sur une branche, il suffit d'utiliser la commande suivante : mkdocs gh-deploy Cela d\u00e9ploiera la documentation sur la branche gh-pages du d\u00e9p\u00f4t, qui est automatiquement servie par GitHub Pages. Project layout data/ # Datasets raw/ # The original, immutable data dump. processed/ # The final, canonical data sets for modeling. interim/ # Intermediate data that has been transformed. external/ # Data from third party sources. docs/ # Documentation index.md # The documentation homepage. ... # Other markdown pages, images and other files . ... # that follow the same structure as the project. notebooks/ # Jupyter notebooks to explore the data and the code. explore_actes.ipynb test_pds_image.ipynb src/ # Source code of this project. domain_knowledge/ # Regex pattern and dictionaries used for data extraction. preprocess/ # Functions for preprocessing PDF files. process/ # Functions for processing PDF files. quality/ # Functions for quality control. utils/ # Utility functions. .gitignore # Specifies intentionally untracked files to ignore. environment-prod.yml # Conda environment file for production. environment.yml # Conda environment file for development. LICENSE # MIT Licence. README.md # The top level README for developers using this project. setup.py # Make this project pip installable with `pip install -e`","title":"Index"},{"location":"#index","text":"Analyse et g\u00e9olocalisation des arr\u00eat\u00e9s de p\u00e9rils sur le territoire de la m\u00e9tropole Aix-Marseille Provence.","title":"Index"},{"location":"#installation","text":"Veuillez suivre les instructions du guide d'installation .","title":"Installation"},{"location":"#utilisation","text":"","title":"Utilisation"},{"location":"#lancement-du-script","text":"Dans le terminal WSL (ou l'invite de commande Ubuntu): Les dossier d'entr\u00e9es et de sorties sont configurables dans le fichier scripts/process.sh . conda activate geo-arretes scripts/process.sh Plusieurs scripts sont d\u00e9finis pour faciliter certaines actions : scripts .","title":"Lancement du script"},{"location":"#planification-de-taches","text":"Le script runner.bat est un exemple de script permettant de lancer le script process.sh (pr\u00e9sent dans le WSL) depuis le Task Scheduler de Windows.","title":"Planification de t\u00e2ches"},{"location":"#logs","text":"Deux types de logs sont disponibles : batch-logs : dans le dossier batch-logs sont stock\u00e9s un court \u00e9tat des lieux de chaque lanc\u00e9 de script. logs : dans le dossier logs sont stock\u00e9s les logs d\u00e9taill\u00e9s de chaque traitement dans le pipeline du script process.sh .","title":"Logs"},{"location":"#documentation","text":"La documentation g\u00e9n\u00e9r\u00e9e \u00e0 partir du code source est disponible \u00e0 l'adresse suivante : https://geo-arretes.github.io/geo-arretes/ . Elle utilise mkdocs et mkdocstrings pour automatiquement g\u00e9n\u00e9rer la documentation \u00e0 partir des docstrings des fonctions et des classes du code source. pip install mkdocs==1.5.3 mkdocstrings==0.23.0 mkdocs-material==9.5.10 Pour pr\u00e9visualiser la documentation localement, il suffit d'utiliser la commande suivante : mkdocs serve La documentation est alors accessible par d\u00e9faut \u00e0 l'adresse suivante : http://127.0.0.1:8000/ Pour d\u00e9ployer la documentation sur une branche, il suffit d'utiliser la commande suivante : mkdocs gh-deploy Cela d\u00e9ploiera la documentation sur la branche gh-pages du d\u00e9p\u00f4t, qui est automatiquement servie par GitHub Pages.","title":"Documentation"},{"location":"#project-layout","text":"data/ # Datasets raw/ # The original, immutable data dump. processed/ # The final, canonical data sets for modeling. interim/ # Intermediate data that has been transformed. external/ # Data from third party sources. docs/ # Documentation index.md # The documentation homepage. ... # Other markdown pages, images and other files . ... # that follow the same structure as the project. notebooks/ # Jupyter notebooks to explore the data and the code. explore_actes.ipynb test_pds_image.ipynb src/ # Source code of this project. domain_knowledge/ # Regex pattern and dictionaries used for data extraction. preprocess/ # Functions for preprocessing PDF files. process/ # Functions for processing PDF files. quality/ # Functions for quality control. utils/ # Utility functions. .gitignore # Specifies intentionally untracked files to ignore. environment-prod.yml # Conda environment file for production. environment.yml # Conda environment file for development. LICENSE # MIT Licence. README.md # The top level README for developers using this project. setup.py # Make this project pip installable with `pip install -e`","title":"Project layout"},{"location":"install/","text":"Guide d'installation Pr\u00e9requis Environnement Linux ou Windows Subsystem for Linux (WSL). L'outil a \u00e9t\u00e9 test\u00e9 sur Ubuntu 20.04 et Windows Subsystem for Linux (WSL) avec Ubuntu 20.04. Installation commune: Ubuntu (natif ou Windows Subsystem for Linux) Dans le terminal WSL (ou l'invite de commande Ubuntu): Installer le mod\u00e8le de Tesseract pour le fran\u00e7ais sudo apt update sudo apt install tesseract-ocr-fra Installer Mambaforge : curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\" bash Mambaforge-$(uname)-$(uname -m).sh Cr\u00e9er un environnement virtuel conda \u00e0 partir du fichier de sp\u00e9cifications environment-prod.yml sh mamba env create --file environment-prod.yml Installer ocrmypdf (maintenant que ses d\u00e9pendances ont \u00e9t\u00e9 install\u00e9es \u00e0 la cr\u00e9ation de l'environnement). conda activate geo-arretes # installer ocrmypdf qui ne pouvait pas \u00eatre install\u00e9 en m\u00eame temps que ses d\u00e9pendances... mamba install ocrmypdf # depuis le dossier o\u00f9 se trouve le code source du projet pip install -e . # d\u00e9sactiver et r\u00e9activer l'environnement virtuel car tesseract, install\u00e9 par ocrmypdf, # a d\u00e9pos\u00e9 ses fichiers de langage dans un sous-dossier # `$HOME/mambaforge/envs/geo-arretes/share/tessdata` # (sinon ils ne seront visibles...) conda deactivate R\u00e9solution de probl\u00e8mes WSL sur Windows Server 2019 Sur des serveurs Windows 2019 ou plus anciens, il peut \u00eatre n\u00e9cessaire d'installer le WSL via une proc\u00e9dure manuelle d\u00e9crite ici . En r\u00e9sum\u00e9 il faut : Activer la fonctionnalit\u00e9 Windows \"Windows Subsystem for Linux\" via la commande Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux . Un red\u00e9marrage du syst\u00e8me est n\u00e9cessaire. T\u00e9l\u00e9charger la distribution Ubuntu 20.04 Renommer le fichier .AppxBundle t\u00e9l\u00e9charg\u00e9 en .zip : Rename-Item .\\CanonicalGroupLimited.UbunutuonWindows_2004.2021.825.0.AppxBundle .\\ubuntu.zip Extraire le fichier zip dans un dossier ubuntu : Expand-Archive .\\ubuntu.zip .\\ubuntu Se d\u00e9placer dans le dossier ubuntu : cd .\\ubuntu Lancer l'archive correspondant \u00e0 votre architecture (par exemple, x64) : Expand-Archive .\\Ubuntu_2004.2021.825.0_x64.zip .\\ubuntu Ajouter le dossier Ubuntu \u00e0 la variable d'environnement PATH : $userenv = [System.Environment]::GetEnvironmentVariable(\"Path\", \"User\") puis [System.Environment]::SetEnvironmentVariable(\"PATH\", $userenv + \";D:\\Logiciels\\Ubuntu\\Ubuntu\", \"User\") Red\u00e9marrer le terminal PowerShell, l'ouvrir en tant qu'administrateur Lancer le fichier ubuntu.exe contenu dans le dossier Ubuntu : .\\ubuntu\\ubuntu\\ubuntu.exe Erreur lors de l'installation de paquets A la cr\u00e9ation de l'environnement conda, si l'installation d'un paquet \u00e9choue avec une erreur \u00e9trange, eg. le paquet vs2015_runtime , suivre la proc\u00e9dure dans https://stackoverflow.com/a/65728405","title":"Guide d'installation"},{"location":"install/#guide-dinstallation","text":"","title":"Guide d'installation"},{"location":"install/#prerequis","text":"Environnement Linux ou Windows Subsystem for Linux (WSL). L'outil a \u00e9t\u00e9 test\u00e9 sur Ubuntu 20.04 et Windows Subsystem for Linux (WSL) avec Ubuntu 20.04.","title":"Pr\u00e9requis"},{"location":"install/#installation-commune-ubuntu-natif-ou-windows-subsystem-for-linux","text":"Dans le terminal WSL (ou l'invite de commande Ubuntu): Installer le mod\u00e8le de Tesseract pour le fran\u00e7ais sudo apt update sudo apt install tesseract-ocr-fra Installer Mambaforge : curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\" bash Mambaforge-$(uname)-$(uname -m).sh Cr\u00e9er un environnement virtuel conda \u00e0 partir du fichier de sp\u00e9cifications environment-prod.yml sh mamba env create --file environment-prod.yml Installer ocrmypdf (maintenant que ses d\u00e9pendances ont \u00e9t\u00e9 install\u00e9es \u00e0 la cr\u00e9ation de l'environnement). conda activate geo-arretes # installer ocrmypdf qui ne pouvait pas \u00eatre install\u00e9 en m\u00eame temps que ses d\u00e9pendances... mamba install ocrmypdf # depuis le dossier o\u00f9 se trouve le code source du projet pip install -e . # d\u00e9sactiver et r\u00e9activer l'environnement virtuel car tesseract, install\u00e9 par ocrmypdf, # a d\u00e9pos\u00e9 ses fichiers de langage dans un sous-dossier # `$HOME/mambaforge/envs/geo-arretes/share/tessdata` # (sinon ils ne seront visibles...) conda deactivate","title":"Installation commune: Ubuntu (natif ou Windows Subsystem for Linux)"},{"location":"install/#resolution-de-problemes","text":"","title":"R\u00e9solution de probl\u00e8mes"},{"location":"install/#wsl-sur-windows-server-2019","text":"Sur des serveurs Windows 2019 ou plus anciens, il peut \u00eatre n\u00e9cessaire d'installer le WSL via une proc\u00e9dure manuelle d\u00e9crite ici . En r\u00e9sum\u00e9 il faut : Activer la fonctionnalit\u00e9 Windows \"Windows Subsystem for Linux\" via la commande Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux . Un red\u00e9marrage du syst\u00e8me est n\u00e9cessaire. T\u00e9l\u00e9charger la distribution Ubuntu 20.04 Renommer le fichier .AppxBundle t\u00e9l\u00e9charg\u00e9 en .zip : Rename-Item .\\CanonicalGroupLimited.UbunutuonWindows_2004.2021.825.0.AppxBundle .\\ubuntu.zip Extraire le fichier zip dans un dossier ubuntu : Expand-Archive .\\ubuntu.zip .\\ubuntu Se d\u00e9placer dans le dossier ubuntu : cd .\\ubuntu Lancer l'archive correspondant \u00e0 votre architecture (par exemple, x64) : Expand-Archive .\\Ubuntu_2004.2021.825.0_x64.zip .\\ubuntu Ajouter le dossier Ubuntu \u00e0 la variable d'environnement PATH : $userenv = [System.Environment]::GetEnvironmentVariable(\"Path\", \"User\") puis [System.Environment]::SetEnvironmentVariable(\"PATH\", $userenv + \";D:\\Logiciels\\Ubuntu\\Ubuntu\", \"User\") Red\u00e9marrer le terminal PowerShell, l'ouvrir en tant qu'administrateur Lancer le fichier ubuntu.exe contenu dans le dossier Ubuntu : .\\ubuntu\\ubuntu\\ubuntu.exe","title":"WSL sur Windows Server 2019"},{"location":"install/#erreur-lors-de-linstallation-de-paquets","text":"A la cr\u00e9ation de l'environnement conda, si l'installation d'un paquet \u00e9choue avec une erreur \u00e9trange, eg. le paquet vs2015_runtime , suivre la proc\u00e9dure dans https://stackoverflow.com/a/65728405","title":"Erreur lors de l'installation de paquets"},{"location":"Code%20Source/domain_knowledge/","text":"Domain Knowledge Definit les expressions r\u00e9guli\u00e8res et les dictionnaires utilis\u00e9s pour l'extraction des donn\u00e9es. Actes Traces de t\u00e9l\u00e9transmission de documents par @ctes. is_accusedereception_page ( page_txt ) D\u00e9tecte si une page contient un accus\u00e9 de r\u00e9ception. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un tampon de transmission is_stamped_page ( page_txt ) D\u00e9tecte si une page contient un tampon (encadr\u00e9) de transmission @actes. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un tampon de transmission Adresses Reconnaissance et traitement des adresses. create_adresse_normalisee ( adr_num , adr_ind , adr_voie , adr_compl , adr_cpostal , adr_ville ) Cr\u00e9er une adresse normalis\u00e9e. L'adresse normalis\u00e9e rassemble les champs extraits de l'adresse brute, et ailleurs dans le document si n\u00e9cessaire (eg. autorit\u00e9 prenant l'arr\u00eat\u00e9, template). Le compl\u00e9ment d'adresse est ignor\u00e9. Parameters: adr_num ( str ) \u2013 Num\u00e9ro de l'adresse adr_ind ( str ) \u2013 Indice de l'adresse adr_voie ( str ) \u2013 Nom de la voie (incluant le type) adr_compl ( str ) \u2013 Compl\u00e9ment d'adresse adr_cpostal ( str ) \u2013 Code postal adr_ville ( str ) \u2013 Commune Returns: adr_norm ( str ) \u2013 Adresse normalis\u00e9e normalize_adresse ( adresse ) Normalise les champs d'adresse. Les formes normales de chaque champ sont: - indice de r\u00e9p\u00e9tition en minuscules, - voie en minuscules, - ville en forme canonique tir\u00e9e du fichier des codes communes INSEE. Les espaces superflues ont normalement \u00e9t\u00e9 supprim\u00e9es en amont. Parameters: adresse ( Dict [ str , str ] ) \u2013 Adresse dont les champs sont bruts. Returns: adresse_norm ( Dict [ str , str ] ) \u2013 Adresse dont les champs sont normalis\u00e9s. process_adresse_brute ( adr_ad_brute ) Extraire une ou plusieurs adresses d'une adresse brute. Chaque adresse comporte diff\u00e9rents champs: num\u00e9ro, indicateur, voie, (\u00e9ventuellement complement d'adresse,) code postal, commune. Parameters: adr_ad_brute ( str ) \u2013 Adresse brute Returns: adresses ( list ( dict ) ) \u2013 Liste d'adresses Agences immobili\u00e8res Reconnaissance des noms d'agences immobili\u00e8res. Certains noms de syndics incluent \"syndic\", les capturer explicitement avant le motif g\u00e9n\u00e9ral permet d'\u00e9viter les conflits. Lister les syndics connus peut acc\u00e9l\u00e9rer et mieux focaliser la capture. normalize_nom_cabinet ( nom_cab ) Normalise un nom de cabinet. La version actuelle requiert une d\u00e9claration explicite dans LISTE_NOMS_CABINETS, mais des traitements de normalisation standard pourraient \u00eatre d\u00e9finis en compl\u00e9ment. Parameters: nom_cab ( str ) \u2013 Nom du cabinet ou de l'agence. Returns: nom_nor ( str ) \u2013 Nom normalis\u00e9. Arr\u00eat\u00e9s Structure d'un arr\u00eat\u00e9 de collectivit\u00e9 territoriale. contains_arrete ( page_txt ) D\u00e9tecte si une page contient ARRET(E|ONS). Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient ARRET(E|ONS) contains_article ( page_txt ) D\u00e9tecte si une page contient un Article. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un Article contains_considerant ( page_txt ) D\u00e9tecte si une page contient un CONSIDERANT. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un CONSIDERANT contains_vu ( page_txt ) D\u00e9tecte si une page contient un VU. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un VU get_commune_maire ( page_txt ) Extrait le nom de la commune pr\u00e9c\u00e9d\u00e9 de la mention du maire. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: nom_commune ( str | None ) \u2013 Nom de la commune si le texte contient une mention du maire, None sinon. get_date ( page_txt ) R\u00e9cup\u00e8re la date de l'arr\u00eat\u00e9. Actuellement, correspond \u00e0 la date de signature, en fin d'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_date ( str ) \u2013 Date du document si trouv\u00e9e, None sinon. get_nom ( page_txt ) R\u00e9cup\u00e8re le nom de l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_nom ( str ) \u2013 Nom de l'arr\u00eat\u00e9 si trouv\u00e9, None sinon. get_num ( page_txt ) R\u00e9cup\u00e8re le num\u00e9ro de l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_num ( str ) \u2013 Num\u00e9ro de l'arr\u00eat\u00e9 si trouv\u00e9, None sinon. Cadastre Reconnaissance et analyse de r\u00e9f\u00e9rences cadastrales. generate_refcadastrale_norm ( codeinsee , refcad , arr_pdf , adr_cpostal ) G\u00e9n\u00e8re une r\u00e9f\u00e9rence cadastrale normalis\u00e9e \u00e0 une entr\u00e9e. Parameters: codeinsee ( str ) \u2013 Code INSEE de la commune. refcad ( str ) \u2013 R\u00e9f\u00e9rence cadastrale brute. arr_pdf ( str ) \u2013 Nom du fichier PDF (pour exception) adr_cpostal ( str ) \u2013 Code postal de la commune Returns: refcad ( string ) \u2013 R\u00e9f\u00e9rence cadastrale normalis\u00e9e. get_parcelles ( page_txt ) R\u00e9cup\u00e8re la ou les r\u00e9f\u00e9rences de parcelles cadastrales. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: id_parcelles ( List [ str ] ) \u2013 R\u00e9f\u00e9rences d'une ou plusieurs parcelles cadastrales si d\u00e9tect\u00e9es dans le texte, liste vide sinon. Cadre r\u00e9glementaire R\u00e9f\u00e9rences au cadre r\u00e9glementaire. contains_cc ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence au Code Civil. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence au Code Civil. contains_cc_art ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 des articles du Code Civil. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 des articles du Code Civil. contains_cch ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence au Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence au Code de la Construction et de l'Habitation. contains_cch_L111 ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article L111 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article L111 du Code de la Construction et de l'Habitation. contains_cch_L511 ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article L511 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article L511 du Code de la Construction et de l'Habitation. contains_cch_L521 ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article L521 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article L521 du Code de la Construction et de l'Habitation. contains_cch_L541 ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article L541 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article L541 du Code de la Construction et de l'Habitation. contains_cch_R511 ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article R511 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article R511 du Code de la Construction et de l'Habitation. contains_cgct ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence au Code G\u00e9n\u00e9ral des Collectivit\u00e9s Territoriales. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence au Code G\u00e9n\u00e9ral des Collectivit\u00e9s Territoriales. contains_cgct_art ( page_txt ) D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 des articles du Code G\u00e9n\u00e9ral des Collectivit\u00e9s Territoriales. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 des articles du Code G\u00e9n\u00e9ral des Collectivit\u00e9s Territoriales. parse_refs_reglement ( txt_body , span_beg , span_end ) Rep\u00e8re dans un texte des r\u00e9f\u00e9rences au cadre r\u00e9glementaire. Parameters: txt_body ( str ) \u2013 Corps de texte \u00e0 analyser main_beg \u2013 D\u00e9but de l'empan \u00e0 analyser. main_end \u2013 Fin de l'empan \u00e0 analyser. Returns: content ( list ) \u2013 Liste d'empans de r\u00e9f\u00e9rences Codes g\u00e9ographiques Acc\u00e8s aux codes g\u00e9ographiques (codes INSEE, codes postaux) des communes. TODO cr\u00e9er des modules similaires pour les autres bases de connaissances: * les variantes de graphies des communes (TODO), * une liste de syndics (TODO). get_codeinsee ( nom_commune , cpostal ) R\u00e9cup\u00e9rer le code INSEE d'une commune. Le code postal est utilis\u00e9 pour les arrondissements de Marseille. Parameters: nom_commune ( str ) \u2013 Nom de la commune cpostal ( str ) \u2013 Code postal, utile pour les arrondissements de Marseille Returns: codeinsee ( string ) \u2013 Code INSEE de la commune. get_codepostal ( nom_commune , codeinsee ) R\u00e9cup\u00e9rer le code postal d'une commune \u00e0 partir de son code INSEE. Attention, risque d'erreurs car certaines communes \u00e9tendues sont couvertes par plusieurs codes postaux: Marseille (1 par arrondissement, chaque arrondissement a aussi son COG) mais aussi Aix-en-Provence (1 COG mais 6 codes postaux: 13080, 13090, 13098, 13100, 13290, 13540), Martigues (codes postaux: 13117, 13500). TODO Le nom de la commune est-il utile? Parameters: nom_commune ( str ) \u2013 Nom de la commune (inutile?) codeinsee ( str ) \u2013 Code INSEE. Returns: cpostal ( string ) \u2013 Code postal de la commune. load_codes_insee_amp () Charger les codes INSEE des communes Actuellement restreint \u00e0 la M\u00e9tropole Aix-Marseille Provence. Returns: df_insee ( DataFrame ) \u2013 Liste des communes avec leur code INSEE. load_codes_postaux_amp () Charger les codes postaux des communes, associ\u00e9s aux codes INSEE. Actuellement restreint \u00e0 la M\u00e9tropole Aix-Marseille Provence. Attention, le fichier actuel (2023-03-18) utilise un s\u00e9parateur \";\". Returns: df_cpostal ( DataFrame ) \u2013 Liste des codes postaux par (code INSEE de) commune. normalize_ville ( raw_ville ) Normalise un nom de ville. Les formes reconnues par S_RE_COMMUNES_VARS sont r\u00e9\u00e9crites dans la forme canonique tir\u00e9e de DF_INSEE[\"commune\"] . Pour les villes absentes de cette ressource externe, le nom est renvoy\u00e9 tel quel. Parameters: raw_ville ( str ) \u2013 Nom brut de la ville, extrait du document. Returns: nor_ville ( str ) \u2013 Forme normale, canonique, du nom de ville. simplify_commune ( com ) Simplifier le nom d'une commune pour faciliter le matching. Parameters: com ( str ) \u2013 Nom de la commune Returns: com_simple ( str ) \u2013 Nom de la commune simplifi\u00e9 Relations entre documents Les r\u00e9f\u00e9rence \u00e0 des documents pr\u00e9c\u00e9dents sont \u00e9nonc\u00e9es dans les \"Vu\". Template de documents Motifs de reconnaissance des en-t\u00eates, pieds-de-page et annexes. TODO - [ ] exploiter les \u00e9l\u00e9ments de template (discriminants) pour d\u00e9terminer la ville (en compl\u00e9ment des autres emplacements: autorit\u00e9, signature) Logements Rep\u00e9rage et extraction de donn\u00e9es propres aux arr\u00eat\u00e9s sur le logement. Propri\u00e9taire, gestionnaire, syndic ou administrateur, adresse de l'immeuble concern\u00e9. get_adr_doc ( page_txt ) Extrait la ou les adresses vis\u00e9es par l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: adresses ( List [ dict ] ) \u2013 La ou les adresses vis\u00e9es par l'arr\u00eat\u00e9, si trouv\u00e9es dans la page de texte. Pour chaque zone d'adresse brute, la ou les adresses extraites. get_gest ( page_txt ) D\u00e9tecte si une page contient un nom de gestionnaire immobilier. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: syndic ( str ) \u2013 Nom de gestionnaire si d\u00e9tect\u00e9, None sinon. get_proprio ( page_txt ) Extrait le nom et l'adresse du propri\u00e9taire. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: syndic ( str ) \u2013 Nom et adresse du propri\u00e9taire si d\u00e9tect\u00e9, None sinon. get_syndic ( page_txt ) D\u00e9tecte si une page contient un nom de syndic. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: syndic ( str ) \u2013 Nom de syndic si d\u00e9tect\u00e9, None sinon. Typologie Typologie des arr\u00eat\u00e9s de mise en s\u00e9curit\u00e9. get_classe ( page_txt ) R\u00e9cup\u00e8re la classification de l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_class ( str ) \u2013 Classification de l'arr\u00eat\u00e9 si trouv\u00e9, None sinon. get_demo ( page_txt ) D\u00e9termine si l'arr\u00eat\u00e9 porte une d\u00e9molition ou d\u00e9construction. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_demol_deconst ( str ) \u2013 D\u00e9molition ou d\u00e9construction si trouv\u00e9, None sinon. get_equ_com ( page_txt ) D\u00e9termine si l'arr\u00eat\u00e9 porte sur la s\u00e9curit\u00e9 des \u00e9quipements communs. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_equ_com ( str ) \u2013 S\u00e9curit\u00e9 des \u00e9quipements communs si trouv\u00e9, None sinon. get_int_hab ( page_txt ) D\u00e9termine si l'arr\u00eat\u00e9 porte interdiction d'habiter et d'occuper. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_int_hab ( str ) \u2013 Interdiction d'habiter si trouv\u00e9, None sinon. get_urgence ( page_txt ) R\u00e9cup\u00e8re le caract\u00e8re d'urgence de l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_class ( str ) \u2013 Caract\u00e8re d'urgence de l'arr\u00eat\u00e9 si trouv\u00e9, None sinon.","title":"Domain Knowledge"},{"location":"Code%20Source/domain_knowledge/#domain-knowledge","text":"Definit les expressions r\u00e9guli\u00e8res et les dictionnaires utilis\u00e9s pour l'extraction des donn\u00e9es.","title":"Domain Knowledge"},{"location":"Code%20Source/domain_knowledge/#actes","text":"Traces de t\u00e9l\u00e9transmission de documents par @ctes.","title":"Actes"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.actes.is_accusedereception_page","text":"D\u00e9tecte si une page contient un accus\u00e9 de r\u00e9ception. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un tampon de transmission","title":"is_accusedereception_page()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.actes.is_stamped_page","text":"D\u00e9tecte si une page contient un tampon (encadr\u00e9) de transmission @actes. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un tampon de transmission","title":"is_stamped_page()"},{"location":"Code%20Source/domain_knowledge/#adresses","text":"Reconnaissance et traitement des adresses.","title":"Adresses"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.adresse.create_adresse_normalisee","text":"Cr\u00e9er une adresse normalis\u00e9e. L'adresse normalis\u00e9e rassemble les champs extraits de l'adresse brute, et ailleurs dans le document si n\u00e9cessaire (eg. autorit\u00e9 prenant l'arr\u00eat\u00e9, template). Le compl\u00e9ment d'adresse est ignor\u00e9. Parameters: adr_num ( str ) \u2013 Num\u00e9ro de l'adresse adr_ind ( str ) \u2013 Indice de l'adresse adr_voie ( str ) \u2013 Nom de la voie (incluant le type) adr_compl ( str ) \u2013 Compl\u00e9ment d'adresse adr_cpostal ( str ) \u2013 Code postal adr_ville ( str ) \u2013 Commune Returns: adr_norm ( str ) \u2013 Adresse normalis\u00e9e","title":"create_adresse_normalisee()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.adresse.normalize_adresse","text":"Normalise les champs d'adresse. Les formes normales de chaque champ sont: - indice de r\u00e9p\u00e9tition en minuscules, - voie en minuscules, - ville en forme canonique tir\u00e9e du fichier des codes communes INSEE. Les espaces superflues ont normalement \u00e9t\u00e9 supprim\u00e9es en amont. Parameters: adresse ( Dict [ str , str ] ) \u2013 Adresse dont les champs sont bruts. Returns: adresse_norm ( Dict [ str , str ] ) \u2013 Adresse dont les champs sont normalis\u00e9s.","title":"normalize_adresse()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.adresse.process_adresse_brute","text":"Extraire une ou plusieurs adresses d'une adresse brute. Chaque adresse comporte diff\u00e9rents champs: num\u00e9ro, indicateur, voie, (\u00e9ventuellement complement d'adresse,) code postal, commune. Parameters: adr_ad_brute ( str ) \u2013 Adresse brute Returns: adresses ( list ( dict ) ) \u2013 Liste d'adresses","title":"process_adresse_brute()"},{"location":"Code%20Source/domain_knowledge/#agences-immobilieres","text":"Reconnaissance des noms d'agences immobili\u00e8res. Certains noms de syndics incluent \"syndic\", les capturer explicitement avant le motif g\u00e9n\u00e9ral permet d'\u00e9viter les conflits. Lister les syndics connus peut acc\u00e9l\u00e9rer et mieux focaliser la capture.","title":"Agences immobili\u00e8res"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.agences_immo.normalize_nom_cabinet","text":"Normalise un nom de cabinet. La version actuelle requiert une d\u00e9claration explicite dans LISTE_NOMS_CABINETS, mais des traitements de normalisation standard pourraient \u00eatre d\u00e9finis en compl\u00e9ment. Parameters: nom_cab ( str ) \u2013 Nom du cabinet ou de l'agence. Returns: nom_nor ( str ) \u2013 Nom normalis\u00e9.","title":"normalize_nom_cabinet()"},{"location":"Code%20Source/domain_knowledge/#arretes","text":"Structure d'un arr\u00eat\u00e9 de collectivit\u00e9 territoriale.","title":"Arr\u00eat\u00e9s"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.arrete.contains_arrete","text":"D\u00e9tecte si une page contient ARRET(E|ONS). Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient ARRET(E|ONS)","title":"contains_arrete()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.arrete.contains_article","text":"D\u00e9tecte si une page contient un Article. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un Article","title":"contains_article()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.arrete.contains_considerant","text":"D\u00e9tecte si une page contient un CONSIDERANT. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un CONSIDERANT","title":"contains_considerant()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.arrete.contains_vu","text":"D\u00e9tecte si une page contient un VU. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient un VU","title":"contains_vu()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.arrete.get_commune_maire","text":"Extrait le nom de la commune pr\u00e9c\u00e9d\u00e9 de la mention du maire. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: nom_commune ( str | None ) \u2013 Nom de la commune si le texte contient une mention du maire, None sinon.","title":"get_commune_maire()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.arrete.get_date","text":"R\u00e9cup\u00e8re la date de l'arr\u00eat\u00e9. Actuellement, correspond \u00e0 la date de signature, en fin d'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_date ( str ) \u2013 Date du document si trouv\u00e9e, None sinon.","title":"get_date()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.arrete.get_nom","text":"R\u00e9cup\u00e8re le nom de l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_nom ( str ) \u2013 Nom de l'arr\u00eat\u00e9 si trouv\u00e9, None sinon.","title":"get_nom()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.arrete.get_num","text":"R\u00e9cup\u00e8re le num\u00e9ro de l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_num ( str ) \u2013 Num\u00e9ro de l'arr\u00eat\u00e9 si trouv\u00e9, None sinon.","title":"get_num()"},{"location":"Code%20Source/domain_knowledge/#cadastre","text":"Reconnaissance et analyse de r\u00e9f\u00e9rences cadastrales.","title":"Cadastre"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadastre.generate_refcadastrale_norm","text":"G\u00e9n\u00e8re une r\u00e9f\u00e9rence cadastrale normalis\u00e9e \u00e0 une entr\u00e9e. Parameters: codeinsee ( str ) \u2013 Code INSEE de la commune. refcad ( str ) \u2013 R\u00e9f\u00e9rence cadastrale brute. arr_pdf ( str ) \u2013 Nom du fichier PDF (pour exception) adr_cpostal ( str ) \u2013 Code postal de la commune Returns: refcad ( string ) \u2013 R\u00e9f\u00e9rence cadastrale normalis\u00e9e.","title":"generate_refcadastrale_norm()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadastre.get_parcelles","text":"R\u00e9cup\u00e8re la ou les r\u00e9f\u00e9rences de parcelles cadastrales. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: id_parcelles ( List [ str ] ) \u2013 R\u00e9f\u00e9rences d'une ou plusieurs parcelles cadastrales si d\u00e9tect\u00e9es dans le texte, liste vide sinon.","title":"get_parcelles()"},{"location":"Code%20Source/domain_knowledge/#cadre-reglementaire","text":"R\u00e9f\u00e9rences au cadre r\u00e9glementaire.","title":"Cadre r\u00e9glementaire"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cc","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence au Code Civil. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence au Code Civil.","title":"contains_cc()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cc_art","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 des articles du Code Civil. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 des articles du Code Civil.","title":"contains_cc_art()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cch","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence au Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence au Code de la Construction et de l'Habitation.","title":"contains_cch()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cch_L111","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article L111 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article L111 du Code de la Construction et de l'Habitation.","title":"contains_cch_L111()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cch_L511","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article L511 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article L511 du Code de la Construction et de l'Habitation.","title":"contains_cch_L511()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cch_L521","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article L521 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article L521 du Code de la Construction et de l'Habitation.","title":"contains_cch_L521()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cch_L541","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article L541 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article L541 du Code de la Construction et de l'Habitation.","title":"contains_cch_L541()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cch_R511","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 l'article R511 du Code de la Construction et de l'Habitation. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 l'article R511 du Code de la Construction et de l'Habitation.","title":"contains_cch_R511()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cgct","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence au Code G\u00e9n\u00e9ral des Collectivit\u00e9s Territoriales. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence au Code G\u00e9n\u00e9ral des Collectivit\u00e9s Territoriales.","title":"contains_cgct()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.contains_cgct_art","text":"D\u00e9tecte si une page contient une r\u00e9f\u00e9rence \u00e0 des articles du Code G\u00e9n\u00e9ral des Collectivit\u00e9s Territoriales. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: has_stamp ( bool ) \u2013 True si le texte contient une r\u00e9f\u00e9rence \u00e0 des articles du Code G\u00e9n\u00e9ral des Collectivit\u00e9s Territoriales.","title":"contains_cgct_art()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.cadre_reglementaire.parse_refs_reglement","text":"Rep\u00e8re dans un texte des r\u00e9f\u00e9rences au cadre r\u00e9glementaire. Parameters: txt_body ( str ) \u2013 Corps de texte \u00e0 analyser main_beg \u2013 D\u00e9but de l'empan \u00e0 analyser. main_end \u2013 Fin de l'empan \u00e0 analyser. Returns: content ( list ) \u2013 Liste d'empans de r\u00e9f\u00e9rences","title":"parse_refs_reglement()"},{"location":"Code%20Source/domain_knowledge/#codes-geographiques","text":"Acc\u00e8s aux codes g\u00e9ographiques (codes INSEE, codes postaux) des communes. TODO cr\u00e9er des modules similaires pour les autres bases de connaissances: * les variantes de graphies des communes (TODO), * une liste de syndics (TODO).","title":"Codes g\u00e9ographiques"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.codes_geo.get_codeinsee","text":"R\u00e9cup\u00e9rer le code INSEE d'une commune. Le code postal est utilis\u00e9 pour les arrondissements de Marseille. Parameters: nom_commune ( str ) \u2013 Nom de la commune cpostal ( str ) \u2013 Code postal, utile pour les arrondissements de Marseille Returns: codeinsee ( string ) \u2013 Code INSEE de la commune.","title":"get_codeinsee()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.codes_geo.get_codepostal","text":"R\u00e9cup\u00e9rer le code postal d'une commune \u00e0 partir de son code INSEE. Attention, risque d'erreurs car certaines communes \u00e9tendues sont couvertes par plusieurs codes postaux: Marseille (1 par arrondissement, chaque arrondissement a aussi son COG) mais aussi Aix-en-Provence (1 COG mais 6 codes postaux: 13080, 13090, 13098, 13100, 13290, 13540), Martigues (codes postaux: 13117, 13500). TODO Le nom de la commune est-il utile? Parameters: nom_commune ( str ) \u2013 Nom de la commune (inutile?) codeinsee ( str ) \u2013 Code INSEE. Returns: cpostal ( string ) \u2013 Code postal de la commune.","title":"get_codepostal()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.codes_geo.load_codes_insee_amp","text":"Charger les codes INSEE des communes Actuellement restreint \u00e0 la M\u00e9tropole Aix-Marseille Provence. Returns: df_insee ( DataFrame ) \u2013 Liste des communes avec leur code INSEE.","title":"load_codes_insee_amp()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.codes_geo.load_codes_postaux_amp","text":"Charger les codes postaux des communes, associ\u00e9s aux codes INSEE. Actuellement restreint \u00e0 la M\u00e9tropole Aix-Marseille Provence. Attention, le fichier actuel (2023-03-18) utilise un s\u00e9parateur \";\". Returns: df_cpostal ( DataFrame ) \u2013 Liste des codes postaux par (code INSEE de) commune.","title":"load_codes_postaux_amp()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.codes_geo.normalize_ville","text":"Normalise un nom de ville. Les formes reconnues par S_RE_COMMUNES_VARS sont r\u00e9\u00e9crites dans la forme canonique tir\u00e9e de DF_INSEE[\"commune\"] . Pour les villes absentes de cette ressource externe, le nom est renvoy\u00e9 tel quel. Parameters: raw_ville ( str ) \u2013 Nom brut de la ville, extrait du document. Returns: nor_ville ( str ) \u2013 Forme normale, canonique, du nom de ville.","title":"normalize_ville()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.codes_geo.simplify_commune","text":"Simplifier le nom d'une commune pour faciliter le matching. Parameters: com ( str ) \u2013 Nom de la commune Returns: com_simple ( str ) \u2013 Nom de la commune simplifi\u00e9","title":"simplify_commune()"},{"location":"Code%20Source/domain_knowledge/#relations-entre-documents","text":"Les r\u00e9f\u00e9rence \u00e0 des documents pr\u00e9c\u00e9dents sont \u00e9nonc\u00e9es dans les \"Vu\".","title":"Relations entre documents"},{"location":"Code%20Source/domain_knowledge/#template-de-documents","text":"Motifs de reconnaissance des en-t\u00eates, pieds-de-page et annexes. TODO - [ ] exploiter les \u00e9l\u00e9ments de template (discriminants) pour d\u00e9terminer la ville (en compl\u00e9ment des autres emplacements: autorit\u00e9, signature)","title":"Template de documents"},{"location":"Code%20Source/domain_knowledge/#logements","text":"Rep\u00e9rage et extraction de donn\u00e9es propres aux arr\u00eat\u00e9s sur le logement. Propri\u00e9taire, gestionnaire, syndic ou administrateur, adresse de l'immeuble concern\u00e9.","title":"Logements"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.logement.get_adr_doc","text":"Extrait la ou les adresses vis\u00e9es par l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: adresses ( List [ dict ] ) \u2013 La ou les adresses vis\u00e9es par l'arr\u00eat\u00e9, si trouv\u00e9es dans la page de texte. Pour chaque zone d'adresse brute, la ou les adresses extraites.","title":"get_adr_doc()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.logement.get_gest","text":"D\u00e9tecte si une page contient un nom de gestionnaire immobilier. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: syndic ( str ) \u2013 Nom de gestionnaire si d\u00e9tect\u00e9, None sinon.","title":"get_gest()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.logement.get_proprio","text":"Extrait le nom et l'adresse du propri\u00e9taire. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: syndic ( str ) \u2013 Nom et adresse du propri\u00e9taire si d\u00e9tect\u00e9, None sinon.","title":"get_proprio()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.logement.get_syndic","text":"D\u00e9tecte si une page contient un nom de syndic. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: syndic ( str ) \u2013 Nom de syndic si d\u00e9tect\u00e9, None sinon.","title":"get_syndic()"},{"location":"Code%20Source/domain_knowledge/#typologie","text":"Typologie des arr\u00eat\u00e9s de mise en s\u00e9curit\u00e9.","title":"Typologie"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.typologie_securite.get_classe","text":"R\u00e9cup\u00e8re la classification de l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_class ( str ) \u2013 Classification de l'arr\u00eat\u00e9 si trouv\u00e9, None sinon.","title":"get_classe()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.typologie_securite.get_demo","text":"D\u00e9termine si l'arr\u00eat\u00e9 porte une d\u00e9molition ou d\u00e9construction. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_demol_deconst ( str ) \u2013 D\u00e9molition ou d\u00e9construction si trouv\u00e9, None sinon.","title":"get_demo()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.typologie_securite.get_equ_com","text":"D\u00e9termine si l'arr\u00eat\u00e9 porte sur la s\u00e9curit\u00e9 des \u00e9quipements communs. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_equ_com ( str ) \u2013 S\u00e9curit\u00e9 des \u00e9quipements communs si trouv\u00e9, None sinon.","title":"get_equ_com()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.typologie_securite.get_int_hab","text":"D\u00e9termine si l'arr\u00eat\u00e9 porte interdiction d'habiter et d'occuper. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_int_hab ( str ) \u2013 Interdiction d'habiter si trouv\u00e9, None sinon.","title":"get_int_hab()"},{"location":"Code%20Source/domain_knowledge/#src.domain_knowledge.typologie_securite.get_urgence","text":"R\u00e9cup\u00e8re le caract\u00e8re d'urgence de l'arr\u00eat\u00e9. Parameters: page_txt ( str ) \u2013 Texte d'une page de document Returns: doc_class ( str ) \u2013 Caract\u00e8re d'urgence de l'arr\u00eat\u00e9 si trouv\u00e9, None sinon.","title":"get_urgence()"},{"location":"Code%20Source/preprocess/","text":"Preprocess Fonctions de pr\u00e9traitements des fichiers PDFs. Convertir les fichiers PDF natifs en PDF/A Utilise ocrmypdf sans appeler le moteur d'OCR. process_files ( df_meta , out_pdf_dir , redo = False , keep_pdfa = False , verbose = 0 ) Convertir les fichiers PDF natifs en PDF/A. Parameters: df_meta ( DataFrame ) \u2013 Liste de fichiers PDF \u00e0 traiter, avec leurs m\u00e9tadonn\u00e9es. out_pdf_dir ( Path ) \u2013 Dossier de sortie pour les PDF/A. redo ( bool , default: False ) \u2013 Si True, r\u00e9analyse les fichiers d\u00e9j\u00e0 trait\u00e9s. keep_pdfa ( bool , default: False ) \u2013 Si True, n'efface pas les fichiers PDF g\u00e9n\u00e9r\u00e9s par l'OCR. verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers d'entr\u00e9e et chemins vers les fichiers PDF/A. Convertir un fichier PDF en PDF/A (archivable) Utilise ocrmypdf. NB: Certaines m\u00e9tadonn\u00e9es du PDF sont perdues https://github.com/ocrmypdf/OCRmyPDF/issues/327 . convert_pdf_to_pdfa ( fp_pdf_in , fp_pdf_out , verbose = 0 ) Convertir un PDF en PDF/A. Utilise ocrmypdf sans appliquer d'OCR. Parameters: verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: returncode ( int ) \u2013 0 si un fichier PDF/A a \u00e9t\u00e9 produit, 1 sinon. Sources de donn\u00e9es D\u00e9terminer le type des fichiers PDF Un fichier peut \u00eatre consid\u00e9r\u00e9 PDF natif (\"texte\") ou non (\"image\"). Le type est d\u00e9termin\u00e9 pour le fichier entier, sans rentrer dans les cas particuliers commme un PDF texte dans lequel une page num\u00e9ris\u00e9e a \u00e9t\u00e9 ins\u00e9r\u00e9e en tant qu'image. Actuellement, de tels fichiers sont probablement consid\u00e9r\u00e9s comme des fichiers PDF non natifs (\"image\"), en se basant sur les m\u00e9tadonn\u00e9es du fichier PDF. guess_pdf_type ( df_row ) Devine le type de PDF: natif (\"texte\") ou non (\"image\") Parameters: df_row ( NamedTuple ) \u2013 M\u00e9tadonn\u00e9es et propri\u00e9t\u00e9s du fichier PDF. Returns: pdf_type ( string, one of {\"text\", \"image\"} ) \u2013 Type de PDF: \"text\" pour les PDF natifs, \"image\" pour les autres qui devront \u00eatre OCRis\u00e9s. process_files ( df_meta ) D\u00e9terminer le type des fichiers PDF. Un fichier PDF peut \u00eatre natif (\"texte\") ou non (\"image\"). Parameters: df_meta ( DataFrame ) \u2013 Liste de fichiers PDF \u00e0 traiter, avec leurs m\u00e9tadonn\u00e9es. Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers d'entr\u00e9e et chemins vers les fichiers PDF/A et TXT. Extrait le texte natif des fichiers PDF avec pdfminer.six N\u00e9cessite d'installer pdfminer.six. Non utilis\u00e9 pour le moment, faute d'avoir identifi\u00e9 les bonnes valeurs des param\u00e8tres utilis\u00e9s pour l'analyse du layout, mais pourrait \u00eatre utile pour r\u00e9-analyser les arr\u00eat\u00e9s de certaines communes avec une mise en page compliqu\u00e9e. extract_native_text_pdfminer ( fp_pdf_in , fp_txt_out , page_beg , page_end ) Extrait le texte natif d'un PDF avec pdfminer.six. Si le texte extrait par pdfminer.six n'est pas vide alors un fichier TXT est produit, sinon aucun fichier TXT n'est produit et un code d'erreur est renvoy\u00e9. Les pages sont s\u00e9par\u00e9es par un \"form feed\" (\" \", \" \" en python). Le texte est normalis\u00e9 en forme NFC (NEW 2023-03-10, NFC plut\u00f4t que NFKC car ce dernier transforme \"\u00ba\" en \"o\"). Parameters: fp_pdf_in ( Path ) \u2013 Fichier PDF d'entr\u00e9e. fp_txt_out ( Path ) \u2013 Fichier TXT produit par extraction directe du texte. page_beg ( int ) \u2013 Num\u00e9ro de la premi\u00e8re page \u00e0 traiter, la premi\u00e8re page d'un PDF est suppos\u00e9e num\u00e9rot\u00e9e 1. page_end ( int ) \u2013 Num\u00e9ro de la derni\u00e8re page \u00e0 traiter (cette page \u00e9tant incluse). Returns: returncode ( int ) \u2013 0 si un fichier TXT a \u00e9t\u00e9 produit, 1 sinon. Extrait le texte natif des fichiers PDF avec pdftotext https://github.com/jalan/pdftotext D\u00e9pendances Windows ( https://github.com/jalan/pdftotext#os-dependencies ): * Microsoft Visual C++ Build Tools: https://visualstudio.microsoft.com/fr/visual-cpp-build-tools/ * poppler ( conda install -c conda-forge poppler ) extract_native_text_pdftotext ( fp_pdf_in , fp_txt_out , page_beg , page_end ) Extrait le texte natif d'un PDF avec pdftotext. Si le texte extrait par pdftotext n'est pas vide alors un fichier TXT est produit, sinon aucun fichier TXT n'est produit et un code d'erreur est renvoy\u00e9. Les pages sont s\u00e9par\u00e9es par un \"form feed\" (\" \", \" \" en python). Le texte est normalis\u00e9 en forme NFC (NEW 2023-03-10, NFC plut\u00f4t que NFKC car ce dernier transforme \"\u00ba\" en \"o\"). Parameters: fp_pdf_in ( Path ) \u2013 Fichier PDF d'entr\u00e9e. fp_txt_out ( Path ) \u2013 Fichier TXT produit par extraction directe du texte. page_beg ( int ) \u2013 Num\u00e9ro de la premi\u00e8re page \u00e0 traiter, la premi\u00e8re page d'un PDF est suppos\u00e9e num\u00e9rot\u00e9e 1. page_end ( int ) \u2013 Num\u00e9ro de la derni\u00e8re page \u00e0 traiter (cette page \u00e9tant incluse). Returns: returncode ( int ) \u2013 0 si un fichier TXT a \u00e9t\u00e9 produit, 1 sinon. Extraire le texte natif des fichiers PDF Le texte natif est extrait avec le wrapper python de l'utilitaire \"pdftotext\" de poppler. Le texte natif repr\u00e9sente: * pour les PDF natifs (\"PDF texte\"), l'int\u00e9gralit\u00e9 du texte ; * pour les PDF non-natifs (\"PDF image\"), du texte extrait par OCR (de qualit\u00e9 variable) ou des fragments de texte issus d'ajout d'objets natifs, eg. tampon, accus\u00e9 de r\u00e9ception. Le texte est normalis\u00e9 en forme NFC: https://docs.python.org/3/howto/unicode.html#comparing-strings . extract_native_text ( df_row , fp_pdf_in , fp_txt_out ) Extrait le texte natif d'un PDF. Parameters: df_row ( NamedTuple ) \u2013 M\u00e9tadonn\u00e9es et informations sur le fichier PDF \u00e0 traiter. fp_pdf_in ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. fp_txt_out ( Path ) \u2013 Chemin du fichier txt contenant le texte extrait. Returns: returncode ( int ) \u2013 Code de retour de l'extraction: 0 si un fichier TXT a \u00e9t\u00e9 produit, 1 sinon. process_files ( df_meta , out_dir_txt , redo = False ) Traiter un ensemble de fichiers PDF: convertir les PDF en PDF/A et extraire le texte. Parameters: df_meta ( DataFrame ) \u2013 Liste de fichiers PDF \u00e0 traiter, avec leurs m\u00e9tadonn\u00e9es. out_dir_txt ( Path ) \u2013 Dossier de sortie pour les fichiers texte. redo ( bool , default: False ) \u2013 Si True, r\u00e9analyse les fichiers d\u00e9j\u00e0 trait\u00e9s. Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers d'entr\u00e9e, chemins vers les fichiers TXT produits et codes de retour de l'extraction de texte natif. Extraire le texte de fichiers PDF par OCR Utilise ocrmypdf. extract_text_from_pdf_image ( fp_pdf_in , fp_txt_out , fp_pdf_out , page_beg , page_end , redo_ocr = False , verbose = 0 ) Extraire le texte d'un PDF image et convertir le fichier en PDF/A. Utilise ocrmypdf. On utilise \"-l fra\" pour am\u00e9liorer la reconnaissance de: \"\u00e0\", \"\u00e8\", \"\u00ea\", apostrophe, \"l'\", \"\u0153\", \"\u00f4\" etc. Parameters: fp_pdf_in ( Path ) \u2013 Fichier PDF image \u00e0 traiter. fp_txt_out ( Path ) \u2013 Fichier TXT produit, contenant le texte extrait par OCR. fp_pdf_out ( Path ) \u2013 Fichier PDF/A produit, incluant le texte oc\u00e9ris\u00e9. page_beg ( int ) \u2013 Num\u00e9ro de la premi\u00e8re page \u00e0 traiter, la premi\u00e8re page d'un PDF est suppos\u00e9e num\u00e9rot\u00e9e 1. page_end ( int ) \u2013 Num\u00e9ro de la derni\u00e8re page \u00e0 traiter (cette page \u00e9tant incluse). redo_ocr ( bool , default: False ) \u2013 Si True, refait l'OCR m\u00eame si une couche d'OCR est d\u00e9tect\u00e9e sur certaines pages. verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: returncode ( int ) \u2013 0 si deux fichiers PDF/A et TXT ont \u00e9t\u00e9 produits, une autre valeur sinon https://ocrmypdf.readthedocs.io/en/latest/advanced.html#return-code-policy . Le texte des PDF non-natifs (\"PDF image\") est extrait avec ocrmypdf. ocrmypdf produit un fichier PDF/A incluant une couche de texte extrait par OCR, et un fichier \"sidecar\" contenant le texte extrait par l'OCR uniquement. Le fichier PDF/A est effac\u00e9, sauf mention contraire explicite par l'option \"keep_pdfa\". preprocess_pdf_file ( df_row , fp_pdf_in , fp_pdf_out , fp_txt_out , verbose = 0 ) Extraire le texte par OCR et g\u00e9n\u00e9rer des fichiers PDF/A et txt. Le fichier PDF est OCRis\u00e9 avec ocrmypdf, qui cr\u00e9e un PDF/A et un fichier texte \"sidecar\". La version actuelle est: ocrmypdf 14.0.3 / Tesseract OCR-PDF 5.2.0 (+ pikepdf 5.6.1). Parameters: df_row ( NamedTuple ) \u2013 M\u00e9tadonn\u00e9es et informations sur le fichier PDF \u00e0 traiter. fp_pdf_in ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. fp_pdf_out ( Path ) \u2013 Chemin du fichier PDF converti en PDF/A (avec OCR le cas \u00e9ch\u00e9ant). fp_txt_out ( Path ) \u2013 Chemin du fichier txt contenant le texte extrait. verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: retcode ( int ) \u2013 Code de retour d'ocrmypdf https://ocrmypdf.readthedocs.io/en/latest/advanced.html#return-code-policy . process_files ( df_meta , out_pdf_dir , out_txt_dir , redo = False , keep_pdfa = False , verbose = 0 ) Traiter un ensemble de fichiers PDF: convertir les PDF en PDF/A et extraire le texte. Parameters: df_meta ( DataFrame ) \u2013 Liste de fichiers PDF \u00e0 traiter, avec leurs m\u00e9tadonn\u00e9es. out_pdf_dir ( Path ) \u2013 Dossier de sortie pour les PDF/A. out_txt_dir ( Path ) \u2013 Dossier de sortie pour les fichiers texte. redo ( bool , default: False ) \u2013 Si True, r\u00e9analyse les fichiers d\u00e9j\u00e0 trait\u00e9s. keep_pdfa ( bool , default: False ) \u2013 Si True, n'efface pas les fichiers PDF g\u00e9n\u00e9r\u00e9s par l'OCR. verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers d'entr\u00e9e et chemins vers les fichiers PDF/A et TXT. Filtrer les fichiers PDF hors du champ de la base de donn\u00e9es Annexes des arr\u00eat\u00e9s: plan de p\u00e9rim\u00e8tre de s\u00e9curit\u00e9, rapports d'expertise etc. TODO filtrer automatiquement \u00e0 partir du texte process_files ( df_meta , df_txts ) Traiter un ensemble d'arr\u00eat\u00e9s: rep\u00e9rer des \u00e9l\u00e9ments de structure des textes. Parameters: df_meta ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des fichiers \u00e0 traiter. df_txts ( DataFrame ) \u2013 Liste de pages de documents \u00e0 traiter. Returns: df_mmod ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des fichiers, filtr\u00e9s. df_tmod ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des pages trait\u00e9es, avec indications des \u00e9l\u00e9ments de structure d\u00e9tect\u00e9s. Indexer un ensemble de fichiers PDF Calcule le hachage de chaque fichier et cr\u00e9e une copie du fichier dans un dossier de travail, en faisant pr\u00e9c\u00e9der le nom du fichier par son hachage. index_folder ( in_dir , out_dir , index_csv , new_csv , recursive = True , digest = 'blake2b' , verbose = False ) Indexer un dossier: hacher et copier les fichiers PDF qu'il contient. Les copies sont renomm\u00e9es en pr\u00e9fixant le nom de chaque fichier par le hachage, afin d'\u00e9viter les conflits de noms de fichiers issus de dossiers diff\u00e9rents. Parameters: in_dir ( Path ) \u2013 Dossier \u00e0 traiter, contenant des PDF. out_dir ( Path ) \u2013 Dossier de sortie, contenant les copies des PDF dont le nom est pr\u00e9c\u00e9d\u00e9 par le hachage. index_csv ( Path ) \u2013 Fichier d'index g\u00e9n\u00e9ral des PDF. new_csv ( Path ) \u2013 Fichier d'index des nouveaux PDF index\u00e9s par cette ex\u00e9cution. recursive ( bool , default: True ) \u2013 Si True, parcourt r\u00e9cursivement le dossier in_dir. digest ( str, defaults to \"blake2b\" , default: 'blake2b' ) \u2013 Algorithme de hachage \u00e0 utiliser https://docs.python.org/3/library/hashlib.html#hash-algorithms . verbose ( bool , default: False ) \u2013 Si True, des warnings sont \u00e9mis \u00e0 chaque anomalie constat\u00e9e dans les m\u00e9tadonn\u00e9es du PDF. Extraire les m\u00e9tadonn\u00e9es des fichiers PDF Ce module utilise pikepdf. get_pdf_info ( fp_pdf , digest = 'blake2b' , verbose = False ) Extraire les informations (dont m\u00e9tadonn\u00e9es) d'un fichier PDF. Utilise actuellement pikepdf. Parameters: fp_pdf ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. digest ( str , default: 'blake2b' ) \u2013 Algorithme de hachage \u00e0 utiliser https://docs.python.org/3/library/hashlib.html#hash-algorithms . verbose ( bool , default: False ) \u2013 Si True, des warnings sont \u00e9mis \u00e0 chaque anomalie constat\u00e9e dans les m\u00e9tadonn\u00e9es du PDF. Returns: pdf_info ( dict ) \u2013 Informations (dont m\u00e9tadonn\u00e9es) du fichier PDF d'entr\u00e9e get_pdf_info_pikepdf ( fp_pdf_in , verbose = False ) Renvoie les infos du PDF en utilisant pikepdf. Les infos incluent un sous-ensemble des m\u00e9tadonn\u00e9es du PDF. Parameters: fp_pdf_in ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. verbose ( bool , default: False ) \u2013 Si True, des warnings sont \u00e9mis \u00e0 chaque anomalie constat\u00e9e dans les m\u00e9tadonn\u00e9es du PDF. Returns: infos ( dict ) \u2013 Dictionnaire contenant les infos du PDF. Traiter les m\u00e9tadonn\u00e9es des fichiers PDF Les traitements permettent de: * d\u00e9tecter les fichiers doublons, * d\u00e9terminer si le PDF est du texte ou image, * d\u00e9terminer si le PDF contient des tampons de t\u00e9l\u00e9transmission en haut des pages, * d\u00e9terminer si le PDF contient une derni\u00e8re page qui est l'accus\u00e9 de r\u00e9ception de la t\u00e9l\u00e9transmission. La liste des tiers de transmission agr\u00e9\u00e9s pour @ctes est sur https://www.collectivites-locales.gouv.fr/sites/default/files/migration/2019_09_13_liste_operateurs_transmission_0.pdf . guess_badocr ( df_meta ) D\u00e9termine si le fichier contient une couche OCR de pi\u00e8tre qualit\u00e9. Arrive quand le champ \"creatortool\" vaut \"Image Capture Plus\". Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es enrichies d'une nouvelle colonne \"guess_badocr\" guess_dernpage_transmission ( df_meta ) D\u00e9termine si la derni\u00e8re page est un accus\u00e9 de r\u00e9ception de t\u00e9l\u00e9transmission. Permet de traiter certains arr\u00eat\u00e9s recueillis apr\u00e8s leur t\u00e9l\u00e9transmission. Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es enrichies d'une nouvelle colonne \"guess_dernpage\" guess_duplicates_meta ( df_meta , hash_fn = 'blake2b' ) D\u00e9termine si les fichiers PDF sont des doublons \u00e0 partir de leurs m\u00e9tadonn\u00e9es. Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF hash_fn ( str , default: 'blake2b' ) \u2013 Nom de la fonction de hachage, doit \u00eatre un nom de colonne du DataFrame de m\u00e9tadonn\u00e9es. Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF, avec des colonnes bool\u00e9ennes \"dup_*\" indiquant les fichiers doublons. guess_pdftext ( df_meta ) D\u00e9termine si le fichier est un PDF texte (ou \"num\u00e9rique natif\"). Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es enrichies d'une nouvelle colonne \"guess_pdftext\" guess_tampon_transmission ( df_meta ) D\u00e9termine si le haut des pages contient des tampons de transmission \u00e9lectronique. Permet de traiter certains arr\u00eat\u00e9s recueillis apr\u00e8s leur t\u00e9l\u00e9transmission. Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es enrichies d'une nouvelle colonne \"guess_tampon\" Charge le texte des documents dans un DataFrame Chaque ligne correspond \u00e0 une page d'un document. create_pages_dataframe ( df_meta ) Charger le texte des documents dans un DataFrame. Une entr\u00e9e par page de document. Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des documents. Returns: df_txts ( DataFrame ) \u2013 Tableau contenant le texte des documents, s\u00e9par\u00e9 par page.","title":"Preprocess"},{"location":"Code%20Source/preprocess/#preprocess","text":"Fonctions de pr\u00e9traitements des fichiers PDFs.","title":"Preprocess"},{"location":"Code%20Source/preprocess/#convertir-les-fichiers-pdf-natifs-en-pdfa","text":"Utilise ocrmypdf sans appeler le moteur d'OCR.","title":"Convertir les fichiers PDF natifs en PDF/A"},{"location":"Code%20Source/preprocess/#src.preprocess.convert_native_pdf_to_pdfa.process_files","text":"Convertir les fichiers PDF natifs en PDF/A. Parameters: df_meta ( DataFrame ) \u2013 Liste de fichiers PDF \u00e0 traiter, avec leurs m\u00e9tadonn\u00e9es. out_pdf_dir ( Path ) \u2013 Dossier de sortie pour les PDF/A. redo ( bool , default: False ) \u2013 Si True, r\u00e9analyse les fichiers d\u00e9j\u00e0 trait\u00e9s. keep_pdfa ( bool , default: False ) \u2013 Si True, n'efface pas les fichiers PDF g\u00e9n\u00e9r\u00e9s par l'OCR. verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers d'entr\u00e9e et chemins vers les fichiers PDF/A.","title":"process_files()"},{"location":"Code%20Source/preprocess/#convertir-un-fichier-pdf-en-pdfa-archivable","text":"Utilise ocrmypdf. NB: Certaines m\u00e9tadonn\u00e9es du PDF sont perdues https://github.com/ocrmypdf/OCRmyPDF/issues/327 .","title":"Convertir un fichier PDF en PDF/A (archivable)"},{"location":"Code%20Source/preprocess/#src.preprocess.convert_to_pdfa.convert_pdf_to_pdfa","text":"Convertir un PDF en PDF/A. Utilise ocrmypdf sans appliquer d'OCR. Parameters: verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: returncode ( int ) \u2013 0 si un fichier PDF/A a \u00e9t\u00e9 produit, 1 sinon.","title":"convert_pdf_to_pdfa()"},{"location":"Code%20Source/preprocess/#sources-de-donnees","text":"","title":"Sources de donn\u00e9es"},{"location":"Code%20Source/preprocess/#determiner-le-type-des-fichiers-pdf","text":"Un fichier peut \u00eatre consid\u00e9r\u00e9 PDF natif (\"texte\") ou non (\"image\"). Le type est d\u00e9termin\u00e9 pour le fichier entier, sans rentrer dans les cas particuliers commme un PDF texte dans lequel une page num\u00e9ris\u00e9e a \u00e9t\u00e9 ins\u00e9r\u00e9e en tant qu'image. Actuellement, de tels fichiers sont probablement consid\u00e9r\u00e9s comme des fichiers PDF non natifs (\"image\"), en se basant sur les m\u00e9tadonn\u00e9es du fichier PDF.","title":"D\u00e9terminer le type des fichiers PDF"},{"location":"Code%20Source/preprocess/#src.preprocess.determine_pdf_type.guess_pdf_type","text":"Devine le type de PDF: natif (\"texte\") ou non (\"image\") Parameters: df_row ( NamedTuple ) \u2013 M\u00e9tadonn\u00e9es et propri\u00e9t\u00e9s du fichier PDF. Returns: pdf_type ( string, one of {\"text\", \"image\"} ) \u2013 Type de PDF: \"text\" pour les PDF natifs, \"image\" pour les autres qui devront \u00eatre OCRis\u00e9s.","title":"guess_pdf_type()"},{"location":"Code%20Source/preprocess/#src.preprocess.determine_pdf_type.process_files","text":"D\u00e9terminer le type des fichiers PDF. Un fichier PDF peut \u00eatre natif (\"texte\") ou non (\"image\"). Parameters: df_meta ( DataFrame ) \u2013 Liste de fichiers PDF \u00e0 traiter, avec leurs m\u00e9tadonn\u00e9es. Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers d'entr\u00e9e et chemins vers les fichiers PDF/A et TXT.","title":"process_files()"},{"location":"Code%20Source/preprocess/#extrait-le-texte-natif-des-fichiers-pdf-avec-pdfminersix","text":"N\u00e9cessite d'installer pdfminer.six. Non utilis\u00e9 pour le moment, faute d'avoir identifi\u00e9 les bonnes valeurs des param\u00e8tres utilis\u00e9s pour l'analyse du layout, mais pourrait \u00eatre utile pour r\u00e9-analyser les arr\u00eat\u00e9s de certaines communes avec une mise en page compliqu\u00e9e.","title":"Extrait le texte natif des fichiers PDF avec pdfminer.six"},{"location":"Code%20Source/preprocess/#src.preprocess.extract_native_text_pdfminer.extract_native_text_pdfminer","text":"Extrait le texte natif d'un PDF avec pdfminer.six. Si le texte extrait par pdfminer.six n'est pas vide alors un fichier TXT est produit, sinon aucun fichier TXT n'est produit et un code d'erreur est renvoy\u00e9. Les pages sont s\u00e9par\u00e9es par un \"form feed\" (\" \", \" \" en python). Le texte est normalis\u00e9 en forme NFC (NEW 2023-03-10, NFC plut\u00f4t que NFKC car ce dernier transforme \"\u00ba\" en \"o\"). Parameters: fp_pdf_in ( Path ) \u2013 Fichier PDF d'entr\u00e9e. fp_txt_out ( Path ) \u2013 Fichier TXT produit par extraction directe du texte. page_beg ( int ) \u2013 Num\u00e9ro de la premi\u00e8re page \u00e0 traiter, la premi\u00e8re page d'un PDF est suppos\u00e9e num\u00e9rot\u00e9e 1. page_end ( int ) \u2013 Num\u00e9ro de la derni\u00e8re page \u00e0 traiter (cette page \u00e9tant incluse). Returns: returncode ( int ) \u2013 0 si un fichier TXT a \u00e9t\u00e9 produit, 1 sinon.","title":"extract_native_text_pdfminer()"},{"location":"Code%20Source/preprocess/#extrait-le-texte-natif-des-fichiers-pdf-avec-pdftotext","text":"https://github.com/jalan/pdftotext D\u00e9pendances Windows ( https://github.com/jalan/pdftotext#os-dependencies ): * Microsoft Visual C++ Build Tools: https://visualstudio.microsoft.com/fr/visual-cpp-build-tools/ * poppler ( conda install -c conda-forge poppler )","title":"Extrait le texte natif des fichiers PDF avec pdftotext"},{"location":"Code%20Source/preprocess/#src.preprocess.extract_native_text_pdftotext.extract_native_text_pdftotext","text":"Extrait le texte natif d'un PDF avec pdftotext. Si le texte extrait par pdftotext n'est pas vide alors un fichier TXT est produit, sinon aucun fichier TXT n'est produit et un code d'erreur est renvoy\u00e9. Les pages sont s\u00e9par\u00e9es par un \"form feed\" (\" \", \" \" en python). Le texte est normalis\u00e9 en forme NFC (NEW 2023-03-10, NFC plut\u00f4t que NFKC car ce dernier transforme \"\u00ba\" en \"o\"). Parameters: fp_pdf_in ( Path ) \u2013 Fichier PDF d'entr\u00e9e. fp_txt_out ( Path ) \u2013 Fichier TXT produit par extraction directe du texte. page_beg ( int ) \u2013 Num\u00e9ro de la premi\u00e8re page \u00e0 traiter, la premi\u00e8re page d'un PDF est suppos\u00e9e num\u00e9rot\u00e9e 1. page_end ( int ) \u2013 Num\u00e9ro de la derni\u00e8re page \u00e0 traiter (cette page \u00e9tant incluse). Returns: returncode ( int ) \u2013 0 si un fichier TXT a \u00e9t\u00e9 produit, 1 sinon.","title":"extract_native_text_pdftotext()"},{"location":"Code%20Source/preprocess/#extraire-le-texte-natif-des-fichiers-pdf","text":"Le texte natif est extrait avec le wrapper python de l'utilitaire \"pdftotext\" de poppler. Le texte natif repr\u00e9sente: * pour les PDF natifs (\"PDF texte\"), l'int\u00e9gralit\u00e9 du texte ; * pour les PDF non-natifs (\"PDF image\"), du texte extrait par OCR (de qualit\u00e9 variable) ou des fragments de texte issus d'ajout d'objets natifs, eg. tampon, accus\u00e9 de r\u00e9ception. Le texte est normalis\u00e9 en forme NFC: https://docs.python.org/3/howto/unicode.html#comparing-strings .","title":"Extraire le texte natif des fichiers PDF"},{"location":"Code%20Source/preprocess/#src.preprocess.extract_native_text.extract_native_text","text":"Extrait le texte natif d'un PDF. Parameters: df_row ( NamedTuple ) \u2013 M\u00e9tadonn\u00e9es et informations sur le fichier PDF \u00e0 traiter. fp_pdf_in ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. fp_txt_out ( Path ) \u2013 Chemin du fichier txt contenant le texte extrait. Returns: returncode ( int ) \u2013 Code de retour de l'extraction: 0 si un fichier TXT a \u00e9t\u00e9 produit, 1 sinon.","title":"extract_native_text()"},{"location":"Code%20Source/preprocess/#src.preprocess.extract_native_text.process_files","text":"Traiter un ensemble de fichiers PDF: convertir les PDF en PDF/A et extraire le texte. Parameters: df_meta ( DataFrame ) \u2013 Liste de fichiers PDF \u00e0 traiter, avec leurs m\u00e9tadonn\u00e9es. out_dir_txt ( Path ) \u2013 Dossier de sortie pour les fichiers texte. redo ( bool , default: False ) \u2013 Si True, r\u00e9analyse les fichiers d\u00e9j\u00e0 trait\u00e9s. Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers d'entr\u00e9e, chemins vers les fichiers TXT produits et codes de retour de l'extraction de texte natif.","title":"process_files()"},{"location":"Code%20Source/preprocess/#extraire-le-texte-de-fichiers-pdf-par-ocr","text":"Utilise ocrmypdf.","title":"Extraire le texte de fichiers PDF par OCR"},{"location":"Code%20Source/preprocess/#src.preprocess.extract_text_ocr_ocrmypdf.extract_text_from_pdf_image","text":"Extraire le texte d'un PDF image et convertir le fichier en PDF/A. Utilise ocrmypdf. On utilise \"-l fra\" pour am\u00e9liorer la reconnaissance de: \"\u00e0\", \"\u00e8\", \"\u00ea\", apostrophe, \"l'\", \"\u0153\", \"\u00f4\" etc. Parameters: fp_pdf_in ( Path ) \u2013 Fichier PDF image \u00e0 traiter. fp_txt_out ( Path ) \u2013 Fichier TXT produit, contenant le texte extrait par OCR. fp_pdf_out ( Path ) \u2013 Fichier PDF/A produit, incluant le texte oc\u00e9ris\u00e9. page_beg ( int ) \u2013 Num\u00e9ro de la premi\u00e8re page \u00e0 traiter, la premi\u00e8re page d'un PDF est suppos\u00e9e num\u00e9rot\u00e9e 1. page_end ( int ) \u2013 Num\u00e9ro de la derni\u00e8re page \u00e0 traiter (cette page \u00e9tant incluse). redo_ocr ( bool , default: False ) \u2013 Si True, refait l'OCR m\u00eame si une couche d'OCR est d\u00e9tect\u00e9e sur certaines pages. verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: returncode ( int ) \u2013 0 si deux fichiers PDF/A et TXT ont \u00e9t\u00e9 produits, une autre valeur sinon https://ocrmypdf.readthedocs.io/en/latest/advanced.html#return-code-policy . Le texte des PDF non-natifs (\"PDF image\") est extrait avec ocrmypdf. ocrmypdf produit un fichier PDF/A incluant une couche de texte extrait par OCR, et un fichier \"sidecar\" contenant le texte extrait par l'OCR uniquement. Le fichier PDF/A est effac\u00e9, sauf mention contraire explicite par l'option \"keep_pdfa\".","title":"extract_text_from_pdf_image()"},{"location":"Code%20Source/preprocess/#src.preprocess.extract_text_ocr.preprocess_pdf_file","text":"Extraire le texte par OCR et g\u00e9n\u00e9rer des fichiers PDF/A et txt. Le fichier PDF est OCRis\u00e9 avec ocrmypdf, qui cr\u00e9e un PDF/A et un fichier texte \"sidecar\". La version actuelle est: ocrmypdf 14.0.3 / Tesseract OCR-PDF 5.2.0 (+ pikepdf 5.6.1). Parameters: df_row ( NamedTuple ) \u2013 M\u00e9tadonn\u00e9es et informations sur le fichier PDF \u00e0 traiter. fp_pdf_in ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. fp_pdf_out ( Path ) \u2013 Chemin du fichier PDF converti en PDF/A (avec OCR le cas \u00e9ch\u00e9ant). fp_txt_out ( Path ) \u2013 Chemin du fichier txt contenant le texte extrait. verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: retcode ( int ) \u2013 Code de retour d'ocrmypdf https://ocrmypdf.readthedocs.io/en/latest/advanced.html#return-code-policy .","title":"preprocess_pdf_file()"},{"location":"Code%20Source/preprocess/#src.preprocess.extract_text_ocr.process_files","text":"Traiter un ensemble de fichiers PDF: convertir les PDF en PDF/A et extraire le texte. Parameters: df_meta ( DataFrame ) \u2013 Liste de fichiers PDF \u00e0 traiter, avec leurs m\u00e9tadonn\u00e9es. out_pdf_dir ( Path ) \u2013 Dossier de sortie pour les PDF/A. out_txt_dir ( Path ) \u2013 Dossier de sortie pour les fichiers texte. redo ( bool , default: False ) \u2013 Si True, r\u00e9analyse les fichiers d\u00e9j\u00e0 trait\u00e9s. keep_pdfa ( bool , default: False ) \u2013 Si True, n'efface pas les fichiers PDF g\u00e9n\u00e9r\u00e9s par l'OCR. verbose ( int , default: 0 ) \u2013 Niveau de verbosit\u00e9 d'ocrmypdf (-1, 0, 1, 2): https://ocrmypdf.readthedocs.io/en/latest/api.html#ocrmypdf.Verbosity Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers d'entr\u00e9e et chemins vers les fichiers PDF/A et TXT.","title":"process_files()"},{"location":"Code%20Source/preprocess/#filtrer-les-fichiers-pdf-hors-du-champ-de-la-base-de-donnees","text":"Annexes des arr\u00eat\u00e9s: plan de p\u00e9rim\u00e8tre de s\u00e9curit\u00e9, rapports d'expertise etc. TODO filtrer automatiquement \u00e0 partir du texte","title":"Filtrer les fichiers PDF hors du champ de la base de donn\u00e9es"},{"location":"Code%20Source/preprocess/#src.preprocess.filter_docs.process_files","text":"Traiter un ensemble d'arr\u00eat\u00e9s: rep\u00e9rer des \u00e9l\u00e9ments de structure des textes. Parameters: df_meta ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des fichiers \u00e0 traiter. df_txts ( DataFrame ) \u2013 Liste de pages de documents \u00e0 traiter. Returns: df_mmod ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des fichiers, filtr\u00e9s. df_tmod ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des pages trait\u00e9es, avec indications des \u00e9l\u00e9ments de structure d\u00e9tect\u00e9s.","title":"process_files()"},{"location":"Code%20Source/preprocess/#indexer-un-ensemble-de-fichiers-pdf","text":"Calcule le hachage de chaque fichier et cr\u00e9e une copie du fichier dans un dossier de travail, en faisant pr\u00e9c\u00e9der le nom du fichier par son hachage.","title":"Indexer un ensemble de fichiers PDF"},{"location":"Code%20Source/preprocess/#src.preprocess.index_pdfs.index_folder","text":"Indexer un dossier: hacher et copier les fichiers PDF qu'il contient. Les copies sont renomm\u00e9es en pr\u00e9fixant le nom de chaque fichier par le hachage, afin d'\u00e9viter les conflits de noms de fichiers issus de dossiers diff\u00e9rents. Parameters: in_dir ( Path ) \u2013 Dossier \u00e0 traiter, contenant des PDF. out_dir ( Path ) \u2013 Dossier de sortie, contenant les copies des PDF dont le nom est pr\u00e9c\u00e9d\u00e9 par le hachage. index_csv ( Path ) \u2013 Fichier d'index g\u00e9n\u00e9ral des PDF. new_csv ( Path ) \u2013 Fichier d'index des nouveaux PDF index\u00e9s par cette ex\u00e9cution. recursive ( bool , default: True ) \u2013 Si True, parcourt r\u00e9cursivement le dossier in_dir. digest ( str, defaults to \"blake2b\" , default: 'blake2b' ) \u2013 Algorithme de hachage \u00e0 utiliser https://docs.python.org/3/library/hashlib.html#hash-algorithms . verbose ( bool , default: False ) \u2013 Si True, des warnings sont \u00e9mis \u00e0 chaque anomalie constat\u00e9e dans les m\u00e9tadonn\u00e9es du PDF.","title":"index_folder()"},{"location":"Code%20Source/preprocess/#extraire-les-metadonnees-des-fichiers-pdf","text":"Ce module utilise pikepdf.","title":"Extraire les m\u00e9tadonn\u00e9es des fichiers PDF"},{"location":"Code%20Source/preprocess/#src.preprocess.pdf_info.get_pdf_info","text":"Extraire les informations (dont m\u00e9tadonn\u00e9es) d'un fichier PDF. Utilise actuellement pikepdf. Parameters: fp_pdf ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. digest ( str , default: 'blake2b' ) \u2013 Algorithme de hachage \u00e0 utiliser https://docs.python.org/3/library/hashlib.html#hash-algorithms . verbose ( bool , default: False ) \u2013 Si True, des warnings sont \u00e9mis \u00e0 chaque anomalie constat\u00e9e dans les m\u00e9tadonn\u00e9es du PDF. Returns: pdf_info ( dict ) \u2013 Informations (dont m\u00e9tadonn\u00e9es) du fichier PDF d'entr\u00e9e","title":"get_pdf_info()"},{"location":"Code%20Source/preprocess/#src.preprocess.pdf_info.get_pdf_info_pikepdf","text":"Renvoie les infos du PDF en utilisant pikepdf. Les infos incluent un sous-ensemble des m\u00e9tadonn\u00e9es du PDF. Parameters: fp_pdf_in ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. verbose ( bool , default: False ) \u2013 Si True, des warnings sont \u00e9mis \u00e0 chaque anomalie constat\u00e9e dans les m\u00e9tadonn\u00e9es du PDF. Returns: infos ( dict ) \u2013 Dictionnaire contenant les infos du PDF.","title":"get_pdf_info_pikepdf()"},{"location":"Code%20Source/preprocess/#traiter-les-metadonnees-des-fichiers-pdf","text":"Les traitements permettent de: * d\u00e9tecter les fichiers doublons, * d\u00e9terminer si le PDF est du texte ou image, * d\u00e9terminer si le PDF contient des tampons de t\u00e9l\u00e9transmission en haut des pages, * d\u00e9terminer si le PDF contient une derni\u00e8re page qui est l'accus\u00e9 de r\u00e9ception de la t\u00e9l\u00e9transmission. La liste des tiers de transmission agr\u00e9\u00e9s pour @ctes est sur https://www.collectivites-locales.gouv.fr/sites/default/files/migration/2019_09_13_liste_operateurs_transmission_0.pdf .","title":"Traiter les m\u00e9tadonn\u00e9es des fichiers PDF"},{"location":"Code%20Source/preprocess/#src.preprocess.process_metadata.guess_badocr","text":"D\u00e9termine si le fichier contient une couche OCR de pi\u00e8tre qualit\u00e9. Arrive quand le champ \"creatortool\" vaut \"Image Capture Plus\". Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es enrichies d'une nouvelle colonne \"guess_badocr\"","title":"guess_badocr()"},{"location":"Code%20Source/preprocess/#src.preprocess.process_metadata.guess_dernpage_transmission","text":"D\u00e9termine si la derni\u00e8re page est un accus\u00e9 de r\u00e9ception de t\u00e9l\u00e9transmission. Permet de traiter certains arr\u00eat\u00e9s recueillis apr\u00e8s leur t\u00e9l\u00e9transmission. Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es enrichies d'une nouvelle colonne \"guess_dernpage\"","title":"guess_dernpage_transmission()"},{"location":"Code%20Source/preprocess/#src.preprocess.process_metadata.guess_duplicates_meta","text":"D\u00e9termine si les fichiers PDF sont des doublons \u00e0 partir de leurs m\u00e9tadonn\u00e9es. Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF hash_fn ( str , default: 'blake2b' ) \u2013 Nom de la fonction de hachage, doit \u00eatre un nom de colonne du DataFrame de m\u00e9tadonn\u00e9es. Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF, avec des colonnes bool\u00e9ennes \"dup_*\" indiquant les fichiers doublons.","title":"guess_duplicates_meta()"},{"location":"Code%20Source/preprocess/#src.preprocess.process_metadata.guess_pdftext","text":"D\u00e9termine si le fichier est un PDF texte (ou \"num\u00e9rique natif\"). Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es enrichies d'une nouvelle colonne \"guess_pdftext\"","title":"guess_pdftext()"},{"location":"Code%20Source/preprocess/#src.preprocess.process_metadata.guess_tampon_transmission","text":"D\u00e9termine si le haut des pages contient des tampons de transmission \u00e9lectronique. Permet de traiter certains arr\u00eat\u00e9s recueillis apr\u00e8s leur t\u00e9l\u00e9transmission. Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des fichiers PDF Returns: df_mmod ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es enrichies d'une nouvelle colonne \"guess_tampon\"","title":"guess_tampon_transmission()"},{"location":"Code%20Source/preprocess/#charge-le-texte-des-documents-dans-un-dataframe","text":"Chaque ligne correspond \u00e0 une page d'un document.","title":"Charge le texte des documents dans un DataFrame"},{"location":"Code%20Source/preprocess/#src.preprocess.separate_pages.create_pages_dataframe","text":"Charger le texte des documents dans un DataFrame. Une entr\u00e9e par page de document. Parameters: df_meta ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es des documents. Returns: df_txts ( DataFrame ) \u2013 Tableau contenant le texte des documents, s\u00e9par\u00e9 par page.","title":"create_pages_dataframe()"},{"location":"Code%20Source/process/","text":"Process Fonctions d'extractions des donn\u00e9es des fichiers pr\u00e9trait\u00e9s. Agr\u00e8ge les pages, et leurs donn\u00e9es extraites, en documents Chaque ligne correspond \u00e0 un document. Les \u00e9ventuelles incoh\u00e9rences entre valeurs extraites pour diff\u00e9rentes pages d'un m\u00eame document sont signal\u00e9es. aggregate_pages ( df_grp , include_actes_page_ar = False ) Fusionne les champs extraits des diff\u00e9rentes pages d'un document. Parameters: df_grp ( DataFrame ) \u2013 Pages d'un document include_actes_page_ar ( bool , default: False ) \u2013 Inclut la page d'accus\u00e9 de r\u00e9ception d'@ctes. Returns: rec_struct ( dict ) \u2013 Dictionnaire de valeurs de diff\u00e9rents types ou nulles, selon que les \u00e9l\u00e9ments ont \u00e9t\u00e9 d\u00e9tect\u00e9s. create_docs_dataframe ( df_pages ) Rassembler les informations des documents dans un DataFrame. Fusionner les entr\u00e9es de chaque page en une entr\u00e9e par document. Parameters: df_pages ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es et donn\u00e9es extraites des pages. Returns: df_docs ( DataFrame ) \u2013 Tableau contenant les m\u00e9tadonn\u00e9es et donn\u00e9es extraites des documents. first ( df_grp , col_on ) Renvoie la premi\u00e8re valeur non-vide de la colonne pagenums ( df_grp , col_on ) Renvoie la liste des num\u00e9ros de pages o\u00f9 une colonne est vraie Enrichit les donn\u00e9es avec des donn\u00e9es suppl\u00e9mentaires Ajoute le code INSEE de la commune. create_docs_dataframe ( df_agg ) Extraire les informations des documents dans un DataFrame. Normaliser et extraire les donn\u00e9es de chaque document en une entr\u00e9e par document. Parameters: df_pages \u2013 M\u00e9tadonn\u00e9es et donn\u00e9es extraites des pages. Returns: df_docs ( DataFrame ) \u2013 Tableau contenant les donn\u00e9es normalis\u00e9es extraites des documents. Exporte les donn\u00e9es en fichiers CSV 4 tables: * arr\u00eat\u00e9, * adresse, * parcelle, * notifi\u00e9 Extraire les donn\u00e9es des documents Les donn\u00e9es sont extraites des empans de texte rep\u00e9r\u00e9s au pr\u00e9alable, et normalis\u00e9es. Lorsque plusieurs empans de texte sont susceptibles de renseigner sur la m\u00eame donn\u00e9e, les diff\u00e9rentes valeurs extraites sont accumul\u00e9es pour certains champs (ex: propri\u00e9taires) ou compar\u00e9es et s\u00e9lectionn\u00e9es pour d'autres champs (ex: commune). create_docs_dataframe ( df_agg ) Extraire les informations des documents dans un DataFrame. Normaliser et extraire les donn\u00e9es de chaque document en une entr\u00e9e par document. Parameters: df_pages \u2013 M\u00e9tadonn\u00e9es et donn\u00e9es extraites des pages. Returns: df_docs ( DataFrame ) \u2013 Tableau contenant les donn\u00e9es normalis\u00e9es extraites des documents. determine_commune ( adr_commune_brute , adr_commune_maire ) D\u00e9terminer la commune de l'adresse vis\u00e9e par l'arr\u00eat\u00e9. R\u00e9concilie la commune \u00e9ventuellement contenue dans l'adresse du ou des b\u00e2timents vis\u00e9s avec le nom de commune extrait du document (template, autorit\u00e9 ou lieu de signature). Parameters: adr_commune_brute ( str ) \u2013 Commune extraite de l'adresse du b\u00e2timent vis\u00e9 par l'arr\u00eat\u00e9. adr_commune_maire ( str ) \u2013 Commune extraite de l'autorit\u00e9 prenant l'arr\u00eat\u00e9, ou du template du document. Returns: adr_commune ( str ) \u2013 Commune de l'adresse vis\u00e9e. Analyse un arr\u00eat\u00e9 et en extrait les donn\u00e9es enrich_adresse ( fn_pdf , adresse , commune_maire ) Consolide et enrichit une adresse, avec ville et codes (INSEE et code postal). Harmonise et compl\u00e8te les informations extraites de l'adresse vis\u00e9e \u00e0 partir des informations extraites du template ou de l'autorit\u00e9 prenant l'arr\u00eat\u00e9. Ajoute une adresse normalis\u00e9e. Parameters: fn_pdf ( str ) \u2013 Nom du fichier PDF (pour debug). adresse ( dict ) \u2013 Adresse vis\u00e9e par le document. commune_maire ( str ) \u2013 Ville extraite du template ou de l'autorit\u00e9 prenant l'arr\u00eat\u00e9. Returns: adresse_enr ( dict ) \u2013 Adresse enrichie et augment\u00e9e. extract_adresses_commune ( fn_pdf , pg_txt_body , commune_maire ) Extraire les adresses vis\u00e9es par l'arr\u00eat\u00e9, et la commune. Parameters: fn_pdf ( str ) \u2013 Nom du fichier PDF de l'arr\u00eat\u00e9 (pour les messages de logs: warnings et erreurs) pg_txt_body ( str ) \u2013 Corps de texte de la page commune_maire ( str ) \u2013 Mention de la commune extraite de l'autorit\u00e9 prenant l'arr\u00eat\u00e9, ou des Returns: adresses ( list ( dict ) ) \u2013 Adresses vis\u00e9es par l'arr\u00eat\u00e9 parse_arrete ( fp_pdf_in , fp_txt_in ) Analyse un arr\u00eat\u00e9 et extrait les donn\u00e9es qu'il contient. L'arr\u00eat\u00e9 est d\u00e9coup\u00e9 en paragraphes puis les donn\u00e9es sont extraites. Parameters: fp_pdf_in ( Path ) \u2013 Fichier PDF source (temporairement?) fp_txt_in ( Path ) \u2013 Fichier texte \u00e0 analyser. Returns: doc_data ( dict ) \u2013 Donn\u00e9es extraites du document. process_files ( df_in , out_dir , date_exec ) Analyse le texte des fichiers PDF extrait dans des fichiers TXT. Parameters: df_in ( DataFrame ) \u2013 Fichier meta_$RUN_otxt.csv contenant les m\u00e9tadonn\u00e9es enrichies et les fichiers PDF et TXT (natif ou OCR) \u00e0 traiter. out_dir ( Path ) \u2013 Dossier de sortie date_exec ( date ) \u2013 Date d'ex\u00e9cution du script, utilis\u00e9e pour (a) le nom des copies de fichiers CSV incluant la date de traitement, (b) l'identifiant unique des arr\u00eat\u00e9s dans les 4 tables, (c) le champ 'datemaj' initialement rempli avec la date d'ex\u00e9cution. Returns: out_files ( Dict [ str , Path ] ) \u2013 Fichiers CSV produits, contenant les donn\u00e9es extraites. Dictionnaire index\u00e9 par les cl\u00e9s {\"adresse\", \"arrete\", \"notifie\", \"parcelle\"}. Analyse le document dans son ensemble Extrait des empans de texte correspondant aux en-t\u00eates, pieds-de-page, autorit\u00e9, vus, correspondants, articles, signature... has_one ( spans , span_typ ) D\u00e9tecte si la liste contient au moins un empan d'un type donn\u00e9. Si la liste est vide, renvoie None. Parameters: spans ( list [ dict ] ) \u2013 Liste d'empans extraits span_typ ( str ) \u2013 Type d'empan recherch\u00e9 Returns: has_span ( boolean ) \u2013 True si au moins un empan de la liste est du type recherch\u00e9. parse_arrete_pages ( fn_pdf , pages ) Analyse les pages de texte d'un arr\u00eat\u00e9. Parameters: fn_pdf ( str ) \u2013 Nom du fichier PDF. pages ( list [ str ] ) \u2013 Liste de pages de texte \u00e0 analyser. Returns: doc_content ( list [ dict ] ) \u2013 Contenu du document, par page d\u00e9coup\u00e9e en zones de texte. parse_doc_postamble ( txt_body , pream_beg , pream_end ) Analyse le postambule d'un document, sur la derni\u00e8re page (hors annexes). Le postambule correspond \u00e0 la zone de signature: date, lieu \u00e9ventuel et signataire. Parameters: txt_body ( str ) \u2013 Corps de texte de la page \u00e0 analyser pream_beg ( int ) \u2013 D\u00e9but de l'empan \u00e0 analyser. pream_end ( int ) \u2013 Fin de l'empan \u00e0 analyser, correspondant au d\u00e9but du 1er \"Vu\". Returns: content ( list ) \u2013 Liste d'empans de contenu parse_doc_preamble ( fn_pdf , txt_body , pream_beg , pream_end ) Analyse le pr\u00e9ambule d'un document, sur la 1re page, avant le 1er \"Vu\". Parameters: fn_pdf ( str ) \u2013 Nom du fichier PDF txt_body ( str ) \u2013 Corps de texte de la page \u00e0 analyser pream_beg ( int ) \u2013 D\u00e9but de l'empan \u00e0 analyser. pream_end ( int ) \u2013 Fin de l'empan \u00e0 analyser, correspondant au d\u00e9but du 1er \"Vu\". Returns: content ( list ) \u2013 Liste d'empans de contenu parse_page_content ( txt_body , main_beg , main_end , cur_state , latest_span ) Analyse une page pour rep\u00e9rer les zones de contenus. Parameters: txt_body ( str ) \u2013 Corps de texte de la page \u00e0 analyser main_beg ( int ) \u2013 D\u00e9but de l'empan \u00e0 analyser. main_end ( int ) \u2013 Fin de l'empan \u00e0 analyser. cur_state ( str ) \u2013 \u00c9tat actuel: \"avant_articles\", \"avant_signature\", \"apres_signature\" latest_span ( Optional [ dict ] ) \u2013 Dernier empan de contenu rep\u00e9r\u00e9 sur la page pr\u00e9c\u00e9dente. Vaut None pour la premi\u00e8re page. Returns: content ( list ) \u2013 Liste d'empans de contenu parse_page_template ( txt ) Analyse une page pour rep\u00e9rer le template. Rep\u00e8re les en-t\u00eates, pieds-de-page, tampons, et renvoie les empans correspondants, ainsi que le texte d\u00e9barrass\u00e9 de ces \u00e9l\u00e9ments de template. Parameters: txt ( str ) \u2013 Texte d'origine de la page. Returns: content ( list ) \u2013 Liste d'empans rep\u00e9r\u00e9s sur la page. txt_body ( string ) \u2013 Corps de texte, d\u00e9fini comme le texte en entr\u00e9e dans lequel les empans d'en-t\u00eates, pieds-de-page et tampons de content ont \u00e9t\u00e9 effac\u00e9s (remplac\u00e9s par des espaces de m\u00eame longueur). process_files ( df_meta , df_txts ) Traiter un ensemble d'arr\u00eat\u00e9s: rep\u00e9rer des \u00e9l\u00e9ments de structure des textes. Parameters: df_meta ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des fichiers \u00e0 traiter. df_txts ( DataFrame ) \u2013 Liste de pages de documents \u00e0 traiter. Returns: df_proc ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des pages trait\u00e9es, avec indications des \u00e9l\u00e9ments de structure d\u00e9tect\u00e9s. unique_txt ( spans , span_typ ) Cherche l'unique empan d'un type donn\u00e9 et renvoie son texte. Si plusieurs empans de la liste en entr\u00e9e sont du type recherch\u00e9, une exception est lev\u00e9e. Si aucun empan de la liste n'est du type recherch\u00e9, renvoie None. Parameters: spans ( list [ dict ] ) \u2013 Liste d'empans extraits span_typ ( str ) \u2013 Type d'empan recherch\u00e9 Returns: span_txt ( str ) \u2013 Texte de l'unique empan du type recherch\u00e9. Extrait la structure des documents D\u00e9coupe chaque arr\u00eat\u00e9 en zones: * pr\u00e9ambule (?), * VUs, * CONSIDERANTs, * ARTICLES, * postambule (?) process_files ( df_meta , df_txts ) Traiter un ensemble d'arr\u00eat\u00e9s: rep\u00e9rer des \u00e9l\u00e9ments de structure des textes. Parameters: df_meta ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des fichiers \u00e0 traiter. df_txts ( DataFrame ) \u2013 Liste de pages de documents \u00e0 traiter. Returns: df_proc ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des pages trait\u00e9es, avec indications des \u00e9l\u00e9ments de structure d\u00e9tect\u00e9s. spot_text_structure ( df_row ) D\u00e9tecte la pr\u00e9sence d'\u00e9l\u00e9ments de structure dans une page d'arr\u00eat\u00e9. D\u00e9tecte la pr\u00e9sence de tampons, pages d'accus\u00e9 de r\u00e9ception, VU, CONSIDERANT, ARTICLE. Parameters: df_row ( NamedTuple ) \u2013 Page de document Returns: rec_struct ( dict ) \u2013 Dictionnaire de valeurs bool\u00e9ennes ou nulles, selon que les \u00e9l\u00e9ments de structure ont \u00e9t\u00e9 d\u00e9tect\u00e9s. Les cl\u00e9s et les types de valeurs sont sp\u00e9cifi\u00e9s dans DTYPE_PARSE . Si df_row ne contient pas de texte, toutes les valeurs de sortie sont None.","title":"Process"},{"location":"Code%20Source/process/#process","text":"Fonctions d'extractions des donn\u00e9es des fichiers pr\u00e9trait\u00e9s.","title":"Process"},{"location":"Code%20Source/process/#agrege-les-pages-et-leurs-donnees-extraites-en-documents","text":"Chaque ligne correspond \u00e0 un document. Les \u00e9ventuelles incoh\u00e9rences entre valeurs extraites pour diff\u00e9rentes pages d'un m\u00eame document sont signal\u00e9es.","title":"Agr\u00e8ge les pages, et leurs donn\u00e9es extraites, en documents"},{"location":"Code%20Source/process/#src.process.aggregate_pages.aggregate_pages","text":"Fusionne les champs extraits des diff\u00e9rentes pages d'un document. Parameters: df_grp ( DataFrame ) \u2013 Pages d'un document include_actes_page_ar ( bool , default: False ) \u2013 Inclut la page d'accus\u00e9 de r\u00e9ception d'@ctes. Returns: rec_struct ( dict ) \u2013 Dictionnaire de valeurs de diff\u00e9rents types ou nulles, selon que les \u00e9l\u00e9ments ont \u00e9t\u00e9 d\u00e9tect\u00e9s.","title":"aggregate_pages()"},{"location":"Code%20Source/process/#src.process.aggregate_pages.create_docs_dataframe","text":"Rassembler les informations des documents dans un DataFrame. Fusionner les entr\u00e9es de chaque page en une entr\u00e9e par document. Parameters: df_pages ( DataFrame ) \u2013 M\u00e9tadonn\u00e9es et donn\u00e9es extraites des pages. Returns: df_docs ( DataFrame ) \u2013 Tableau contenant les m\u00e9tadonn\u00e9es et donn\u00e9es extraites des documents.","title":"create_docs_dataframe()"},{"location":"Code%20Source/process/#src.process.aggregate_pages.first","text":"Renvoie la premi\u00e8re valeur non-vide de la colonne","title":"first()"},{"location":"Code%20Source/process/#src.process.aggregate_pages.pagenums","text":"Renvoie la liste des num\u00e9ros de pages o\u00f9 une colonne est vraie","title":"pagenums()"},{"location":"Code%20Source/process/#enrichit-les-donnees-avec-des-donnees-supplementaires","text":"Ajoute le code INSEE de la commune.","title":"Enrichit les donn\u00e9es avec des donn\u00e9es suppl\u00e9mentaires"},{"location":"Code%20Source/process/#src.process.enrich_data.create_docs_dataframe","text":"Extraire les informations des documents dans un DataFrame. Normaliser et extraire les donn\u00e9es de chaque document en une entr\u00e9e par document. Parameters: df_pages \u2013 M\u00e9tadonn\u00e9es et donn\u00e9es extraites des pages. Returns: df_docs ( DataFrame ) \u2013 Tableau contenant les donn\u00e9es normalis\u00e9es extraites des documents.","title":"create_docs_dataframe()"},{"location":"Code%20Source/process/#exporte-les-donnees-en-fichiers-csv","text":"4 tables: * arr\u00eat\u00e9, * adresse, * parcelle, * notifi\u00e9","title":"Exporte les donn\u00e9es en fichiers CSV"},{"location":"Code%20Source/process/#extraire-les-donnees-des-documents","text":"Les donn\u00e9es sont extraites des empans de texte rep\u00e9r\u00e9s au pr\u00e9alable, et normalis\u00e9es. Lorsque plusieurs empans de texte sont susceptibles de renseigner sur la m\u00eame donn\u00e9e, les diff\u00e9rentes valeurs extraites sont accumul\u00e9es pour certains champs (ex: propri\u00e9taires) ou compar\u00e9es et s\u00e9lectionn\u00e9es pour d'autres champs (ex: commune).","title":"Extraire les donn\u00e9es des documents"},{"location":"Code%20Source/process/#src.process.extract_data.create_docs_dataframe","text":"Extraire les informations des documents dans un DataFrame. Normaliser et extraire les donn\u00e9es de chaque document en une entr\u00e9e par document. Parameters: df_pages \u2013 M\u00e9tadonn\u00e9es et donn\u00e9es extraites des pages. Returns: df_docs ( DataFrame ) \u2013 Tableau contenant les donn\u00e9es normalis\u00e9es extraites des documents.","title":"create_docs_dataframe()"},{"location":"Code%20Source/process/#src.process.extract_data.determine_commune","text":"D\u00e9terminer la commune de l'adresse vis\u00e9e par l'arr\u00eat\u00e9. R\u00e9concilie la commune \u00e9ventuellement contenue dans l'adresse du ou des b\u00e2timents vis\u00e9s avec le nom de commune extrait du document (template, autorit\u00e9 ou lieu de signature). Parameters: adr_commune_brute ( str ) \u2013 Commune extraite de l'adresse du b\u00e2timent vis\u00e9 par l'arr\u00eat\u00e9. adr_commune_maire ( str ) \u2013 Commune extraite de l'autorit\u00e9 prenant l'arr\u00eat\u00e9, ou du template du document. Returns: adr_commune ( str ) \u2013 Commune de l'adresse vis\u00e9e.","title":"determine_commune()"},{"location":"Code%20Source/process/#analyse-un-arrete-et-en-extrait-les-donnees","text":"","title":"Analyse un arr\u00eat\u00e9 et en extrait les donn\u00e9es"},{"location":"Code%20Source/process/#src.process.parse_doc_direct.enrich_adresse","text":"Consolide et enrichit une adresse, avec ville et codes (INSEE et code postal). Harmonise et compl\u00e8te les informations extraites de l'adresse vis\u00e9e \u00e0 partir des informations extraites du template ou de l'autorit\u00e9 prenant l'arr\u00eat\u00e9. Ajoute une adresse normalis\u00e9e. Parameters: fn_pdf ( str ) \u2013 Nom du fichier PDF (pour debug). adresse ( dict ) \u2013 Adresse vis\u00e9e par le document. commune_maire ( str ) \u2013 Ville extraite du template ou de l'autorit\u00e9 prenant l'arr\u00eat\u00e9. Returns: adresse_enr ( dict ) \u2013 Adresse enrichie et augment\u00e9e.","title":"enrich_adresse()"},{"location":"Code%20Source/process/#src.process.parse_doc_direct.extract_adresses_commune","text":"Extraire les adresses vis\u00e9es par l'arr\u00eat\u00e9, et la commune. Parameters: fn_pdf ( str ) \u2013 Nom du fichier PDF de l'arr\u00eat\u00e9 (pour les messages de logs: warnings et erreurs) pg_txt_body ( str ) \u2013 Corps de texte de la page commune_maire ( str ) \u2013 Mention de la commune extraite de l'autorit\u00e9 prenant l'arr\u00eat\u00e9, ou des Returns: adresses ( list ( dict ) ) \u2013 Adresses vis\u00e9es par l'arr\u00eat\u00e9","title":"extract_adresses_commune()"},{"location":"Code%20Source/process/#src.process.parse_doc_direct.parse_arrete","text":"Analyse un arr\u00eat\u00e9 et extrait les donn\u00e9es qu'il contient. L'arr\u00eat\u00e9 est d\u00e9coup\u00e9 en paragraphes puis les donn\u00e9es sont extraites. Parameters: fp_pdf_in ( Path ) \u2013 Fichier PDF source (temporairement?) fp_txt_in ( Path ) \u2013 Fichier texte \u00e0 analyser. Returns: doc_data ( dict ) \u2013 Donn\u00e9es extraites du document.","title":"parse_arrete()"},{"location":"Code%20Source/process/#src.process.parse_doc_direct.process_files","text":"Analyse le texte des fichiers PDF extrait dans des fichiers TXT. Parameters: df_in ( DataFrame ) \u2013 Fichier meta_$RUN_otxt.csv contenant les m\u00e9tadonn\u00e9es enrichies et les fichiers PDF et TXT (natif ou OCR) \u00e0 traiter. out_dir ( Path ) \u2013 Dossier de sortie date_exec ( date ) \u2013 Date d'ex\u00e9cution du script, utilis\u00e9e pour (a) le nom des copies de fichiers CSV incluant la date de traitement, (b) l'identifiant unique des arr\u00eat\u00e9s dans les 4 tables, (c) le champ 'datemaj' initialement rempli avec la date d'ex\u00e9cution. Returns: out_files ( Dict [ str , Path ] ) \u2013 Fichiers CSV produits, contenant les donn\u00e9es extraites. Dictionnaire index\u00e9 par les cl\u00e9s {\"adresse\", \"arrete\", \"notifie\", \"parcelle\"}.","title":"process_files()"},{"location":"Code%20Source/process/#analyse-le-document-dans-son-ensemble","text":"Extrait des empans de texte correspondant aux en-t\u00eates, pieds-de-page, autorit\u00e9, vus, correspondants, articles, signature...","title":"Analyse le document dans son ensemble"},{"location":"Code%20Source/process/#src.process.parse_doc.has_one","text":"D\u00e9tecte si la liste contient au moins un empan d'un type donn\u00e9. Si la liste est vide, renvoie None. Parameters: spans ( list [ dict ] ) \u2013 Liste d'empans extraits span_typ ( str ) \u2013 Type d'empan recherch\u00e9 Returns: has_span ( boolean ) \u2013 True si au moins un empan de la liste est du type recherch\u00e9.","title":"has_one()"},{"location":"Code%20Source/process/#src.process.parse_doc.parse_arrete_pages","text":"Analyse les pages de texte d'un arr\u00eat\u00e9. Parameters: fn_pdf ( str ) \u2013 Nom du fichier PDF. pages ( list [ str ] ) \u2013 Liste de pages de texte \u00e0 analyser. Returns: doc_content ( list [ dict ] ) \u2013 Contenu du document, par page d\u00e9coup\u00e9e en zones de texte.","title":"parse_arrete_pages()"},{"location":"Code%20Source/process/#src.process.parse_doc.parse_doc_postamble","text":"Analyse le postambule d'un document, sur la derni\u00e8re page (hors annexes). Le postambule correspond \u00e0 la zone de signature: date, lieu \u00e9ventuel et signataire. Parameters: txt_body ( str ) \u2013 Corps de texte de la page \u00e0 analyser pream_beg ( int ) \u2013 D\u00e9but de l'empan \u00e0 analyser. pream_end ( int ) \u2013 Fin de l'empan \u00e0 analyser, correspondant au d\u00e9but du 1er \"Vu\". Returns: content ( list ) \u2013 Liste d'empans de contenu","title":"parse_doc_postamble()"},{"location":"Code%20Source/process/#src.process.parse_doc.parse_doc_preamble","text":"Analyse le pr\u00e9ambule d'un document, sur la 1re page, avant le 1er \"Vu\". Parameters: fn_pdf ( str ) \u2013 Nom du fichier PDF txt_body ( str ) \u2013 Corps de texte de la page \u00e0 analyser pream_beg ( int ) \u2013 D\u00e9but de l'empan \u00e0 analyser. pream_end ( int ) \u2013 Fin de l'empan \u00e0 analyser, correspondant au d\u00e9but du 1er \"Vu\". Returns: content ( list ) \u2013 Liste d'empans de contenu","title":"parse_doc_preamble()"},{"location":"Code%20Source/process/#src.process.parse_doc.parse_page_content","text":"Analyse une page pour rep\u00e9rer les zones de contenus. Parameters: txt_body ( str ) \u2013 Corps de texte de la page \u00e0 analyser main_beg ( int ) \u2013 D\u00e9but de l'empan \u00e0 analyser. main_end ( int ) \u2013 Fin de l'empan \u00e0 analyser. cur_state ( str ) \u2013 \u00c9tat actuel: \"avant_articles\", \"avant_signature\", \"apres_signature\" latest_span ( Optional [ dict ] ) \u2013 Dernier empan de contenu rep\u00e9r\u00e9 sur la page pr\u00e9c\u00e9dente. Vaut None pour la premi\u00e8re page. Returns: content ( list ) \u2013 Liste d'empans de contenu","title":"parse_page_content()"},{"location":"Code%20Source/process/#src.process.parse_doc.parse_page_template","text":"Analyse une page pour rep\u00e9rer le template. Rep\u00e8re les en-t\u00eates, pieds-de-page, tampons, et renvoie les empans correspondants, ainsi que le texte d\u00e9barrass\u00e9 de ces \u00e9l\u00e9ments de template. Parameters: txt ( str ) \u2013 Texte d'origine de la page. Returns: content ( list ) \u2013 Liste d'empans rep\u00e9r\u00e9s sur la page. txt_body ( string ) \u2013 Corps de texte, d\u00e9fini comme le texte en entr\u00e9e dans lequel les empans d'en-t\u00eates, pieds-de-page et tampons de content ont \u00e9t\u00e9 effac\u00e9s (remplac\u00e9s par des espaces de m\u00eame longueur).","title":"parse_page_template()"},{"location":"Code%20Source/process/#src.process.parse_doc.process_files","text":"Traiter un ensemble d'arr\u00eat\u00e9s: rep\u00e9rer des \u00e9l\u00e9ments de structure des textes. Parameters: df_meta ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des fichiers \u00e0 traiter. df_txts ( DataFrame ) \u2013 Liste de pages de documents \u00e0 traiter. Returns: df_proc ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des pages trait\u00e9es, avec indications des \u00e9l\u00e9ments de structure d\u00e9tect\u00e9s.","title":"process_files()"},{"location":"Code%20Source/process/#src.process.parse_doc.unique_txt","text":"Cherche l'unique empan d'un type donn\u00e9 et renvoie son texte. Si plusieurs empans de la liste en entr\u00e9e sont du type recherch\u00e9, une exception est lev\u00e9e. Si aucun empan de la liste n'est du type recherch\u00e9, renvoie None. Parameters: spans ( list [ dict ] ) \u2013 Liste d'empans extraits span_typ ( str ) \u2013 Type d'empan recherch\u00e9 Returns: span_txt ( str ) \u2013 Texte de l'unique empan du type recherch\u00e9.","title":"unique_txt()"},{"location":"Code%20Source/process/#extrait-la-structure-des-documents","text":"D\u00e9coupe chaque arr\u00eat\u00e9 en zones: * pr\u00e9ambule (?), * VUs, * CONSIDERANTs, * ARTICLES, * postambule (?)","title":"Extrait la structure des documents"},{"location":"Code%20Source/process/#src.process.parse_native_pages.process_files","text":"Traiter un ensemble d'arr\u00eat\u00e9s: rep\u00e9rer des \u00e9l\u00e9ments de structure des textes. Parameters: df_meta ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des fichiers \u00e0 traiter. df_txts ( DataFrame ) \u2013 Liste de pages de documents \u00e0 traiter. Returns: df_proc ( DataFrame ) \u2013 Liste de m\u00e9tadonn\u00e9es des pages trait\u00e9es, avec indications des \u00e9l\u00e9ments de structure d\u00e9tect\u00e9s.","title":"process_files()"},{"location":"Code%20Source/process/#src.process.parse_native_pages.spot_text_structure","text":"D\u00e9tecte la pr\u00e9sence d'\u00e9l\u00e9ments de structure dans une page d'arr\u00eat\u00e9. D\u00e9tecte la pr\u00e9sence de tampons, pages d'accus\u00e9 de r\u00e9ception, VU, CONSIDERANT, ARTICLE. Parameters: df_row ( NamedTuple ) \u2013 Page de document Returns: rec_struct ( dict ) \u2013 Dictionnaire de valeurs bool\u00e9ennes ou nulles, selon que les \u00e9l\u00e9ments de structure ont \u00e9t\u00e9 d\u00e9tect\u00e9s. Les cl\u00e9s et les types de valeurs sont sp\u00e9cifi\u00e9s dans DTYPE_PARSE . Si df_row ne contient pas de texte, toutes les valeurs de sortie sont None.","title":"spot_text_structure()"},{"location":"Code%20Source/quality/","text":"Quality Fonctions de validation des donn\u00e9es extraites. Valider les zones rep\u00e9r\u00e9es Tous les en-t\u00eates commencent \u00e0 0 ; Tous les pieds-de-pages terminent \u00e0 la longueur du document ; En-t\u00eate et pied-de-page sont disjoints ; drop_no_errors_arr ( df_arr ) Supprime les arr\u00eat\u00e9s sans erreur. Parameters: df_arr ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df_arr ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s sans erreurs. error_classe_manquante ( df ) Signale les arr\u00eat\u00e9s dont la classe n'a pu \u00eatre d\u00e9termin\u00e9e. Les causes les plus fr\u00e9quentes sont une erreur d'OCR sur un document mal num\u00e9ris\u00e9, ou une mise en page du document sur plusieurs colonnes qui n'est pas explicitement g\u00e9r\u00e9e par les scripts actuels, et dont le r\u00e9sultat ne permet pas la reconnaissance des motifs recherch\u00e9s. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. error_codeinsee_13055 ( df ) Signale les arr\u00eat\u00e9s dont le code INSEE est 13055. 13055 est le code pour tout Marseille, alors que l'on devrait avoir le code propre \u00e0 l'arrondissement (13201 \u00e0 13216). Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. error_codeinsee_manquant ( df ) Signale les arr\u00eat\u00e9s dont le code INSEE est manquant. Le code INSEE est d\u00e9termin\u00e9 sur base du nom de la commune, crois\u00e9 avec la table des codes communes dans data/external/ (actuellement restreint au p\u00e9rim\u00e8tre de la m\u00e9tropole Aix-Marseille Provence). Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. error_cpostal_manquant ( df ) Signale les adresses d'arr\u00eat\u00e9s sans ville. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: certaines mainlev\u00e9es ou abrogations), ou pas d'adresse incluant la ville, auquel cas la ville est d\u00e9termin\u00e9e selon d'autres indices (ex: lieu de signature), sinon recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer ou \u00e0 analyser correctement. Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. error_date_manquante ( df ) Signale les arr\u00eat\u00e9s dont la date n'a pu \u00eatre d\u00e9termin\u00e9e. La cause la plus fr\u00e9quente est une erreur d'OCR sur une date manuscrite ou tamponn\u00e9e, ou un document mal num\u00e9ris\u00e9 ; il est possible que le script \u00e9choue \u00e0 extraire la date dans certaines tournures de r\u00e9daction. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. error_num_voie_manquant ( df ) Signale les adresses d'arr\u00eat\u00e9s sans num\u00e9ro de voie. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: certaines mainlev\u00e9es ou abrogations), auquel cas cette information doit \u00eatre recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer ou \u00e0 analyser correctement ou totalement. Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. error_urgence_manquante ( df ) Signale les arr\u00eat\u00e9s dont l'urgence n'a pu \u00eatre d\u00e9termin\u00e9e. La cause la plus fr\u00e9quente est une classe d'arr\u00eat\u00e9 qui ne donne pas explicitement cette information. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. error_ville_manquante ( df ) Signale les adresses d'arr\u00eat\u00e9s sans ville. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: certaines mainlev\u00e9es ou abrogations), ou pas d'adresse incluant la ville, auquel cas la ville est d\u00e9termin\u00e9e selon d'autres indices (ex: lieu de signature), sinon recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer ou \u00e0 analyser correctement. Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. error_voie_manquante ( df ) Signale les adresses d'arr\u00eat\u00e9s sans voie. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: certaines mainlev\u00e9es ou abrogations), auquel cas cette information doit \u00eatre recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer ou \u00e0 analyser correctement. Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. examine_doc_content ( fn_pdf , doc_content ) V\u00e9rifie des hypoth\u00e8ses de bonne formation sur le contenu extrait du document. Parameters: doc_content ( list [ dict ] ) \u2013 Empans de contenu extraits du document expect_footer_end_len ( df ) V\u00e9rifie que les en-t\u00eates commencent tous \u00e0 0. Ignore les valeurs manquantes (aucun en-t\u00eate d\u00e9tect\u00e9). Parameters: df ( DataFrame ) \u2013 DataFrame contenant les zones rep\u00e9r\u00e9es dans les documents. Returns: success ( bool ) \u2013 True si tous les en-t\u00eates d\u00e9tect\u00e9s commencent \u00e0 0. expect_header_beg_zero ( df ) V\u00e9rifie que les en-t\u00eates commencent tous \u00e0 0. Ignore les valeurs manquantes (aucun en-t\u00eate d\u00e9tect\u00e9). Parameters: df ( DataFrame ) \u2013 DataFrame contenant les zones rep\u00e9r\u00e9es dans les documents. Returns: success ( bool ) \u2013 True si tous les en-t\u00eates d\u00e9tect\u00e9s commencent \u00e0 0. generate_html_report ( run , df_adr , df_arr , df_not , df_par ) G\u00e9n\u00e9rer un rapport d'erreurs en HTML Parameters: run ( str ) \u2013 Identifiant de l'ex\u00e9cution df_adr ( DataFrame ) \u2013 Adresses df_arr ( DataFrame ) \u2013 Arr\u00eat\u00e9s df_not ( DataFrame ) \u2013 Notifi\u00e9s df_par ( DataFrame ) \u2013 Parcelles Returns: html_report ( string ) \u2013 Rapport HTML warn_adresse_empty ( df ) Signale les arr\u00eat\u00e9s sans aucune adresse. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: mainlev\u00e9e, abrogation), auquel cas cette information doit \u00eatre recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer. Ignore les valeurs manquantes. C'est une erreur pour l'utilisateur final mais un warning du point de vue du script, car la probabilit\u00e9 que l'adresse ne soit pas dans l'arr\u00eat\u00e9, sachant qu'aucune adresse n'a \u00e9t\u00e9 extraite, est relativement \u00e9lev\u00e9e. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente. warn_par_ref_cad_empty ( df ) Signale les arr\u00eat\u00e9s sans aucune r\u00e9f\u00e9rence de parcelle cadastrale. Certains arr\u00eat\u00e9s ne contiennent pas de r\u00e9f\u00e9rence cadastrale, auquel cas cette information doit \u00eatre recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs r\u00e9f\u00e9rences cadastrales que les scripts \u00e9chouent \u00e0 rep\u00e9rer. Ignore les valeurs manquantes. C'est une erreur pour l'utilisateur final mais un warning du point de vue du script, car la probabilit\u00e9 que la r\u00e9f\u00e9rence ne soit pas dans l'arr\u00eat\u00e9, sachant qu'aucune r\u00e9f\u00e9rence n'a \u00e9t\u00e9 extraite, est \u00e9lev\u00e9e. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"Quality"},{"location":"Code%20Source/quality/#quality","text":"Fonctions de validation des donn\u00e9es extraites.","title":"Quality"},{"location":"Code%20Source/quality/#valider-les-zones-reperees","text":"Tous les en-t\u00eates commencent \u00e0 0 ; Tous les pieds-de-pages terminent \u00e0 la longueur du document ; En-t\u00eate et pied-de-page sont disjoints ;","title":"Valider les zones rep\u00e9r\u00e9es"},{"location":"Code%20Source/quality/#src.quality.validate_parses.drop_no_errors_arr","text":"Supprime les arr\u00eat\u00e9s sans erreur. Parameters: df_arr ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df_arr ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s sans erreurs.","title":"drop_no_errors_arr()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.error_classe_manquante","text":"Signale les arr\u00eat\u00e9s dont la classe n'a pu \u00eatre d\u00e9termin\u00e9e. Les causes les plus fr\u00e9quentes sont une erreur d'OCR sur un document mal num\u00e9ris\u00e9, ou une mise en page du document sur plusieurs colonnes qui n'est pas explicitement g\u00e9r\u00e9e par les scripts actuels, et dont le r\u00e9sultat ne permet pas la reconnaissance des motifs recherch\u00e9s. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"error_classe_manquante()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.error_codeinsee_13055","text":"Signale les arr\u00eat\u00e9s dont le code INSEE est 13055. 13055 est le code pour tout Marseille, alors que l'on devrait avoir le code propre \u00e0 l'arrondissement (13201 \u00e0 13216). Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"error_codeinsee_13055()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.error_codeinsee_manquant","text":"Signale les arr\u00eat\u00e9s dont le code INSEE est manquant. Le code INSEE est d\u00e9termin\u00e9 sur base du nom de la commune, crois\u00e9 avec la table des codes communes dans data/external/ (actuellement restreint au p\u00e9rim\u00e8tre de la m\u00e9tropole Aix-Marseille Provence). Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"error_codeinsee_manquant()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.error_cpostal_manquant","text":"Signale les adresses d'arr\u00eat\u00e9s sans ville. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: certaines mainlev\u00e9es ou abrogations), ou pas d'adresse incluant la ville, auquel cas la ville est d\u00e9termin\u00e9e selon d'autres indices (ex: lieu de signature), sinon recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer ou \u00e0 analyser correctement. Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"error_cpostal_manquant()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.error_date_manquante","text":"Signale les arr\u00eat\u00e9s dont la date n'a pu \u00eatre d\u00e9termin\u00e9e. La cause la plus fr\u00e9quente est une erreur d'OCR sur une date manuscrite ou tamponn\u00e9e, ou un document mal num\u00e9ris\u00e9 ; il est possible que le script \u00e9choue \u00e0 extraire la date dans certaines tournures de r\u00e9daction. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"error_date_manquante()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.error_num_voie_manquant","text":"Signale les adresses d'arr\u00eat\u00e9s sans num\u00e9ro de voie. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: certaines mainlev\u00e9es ou abrogations), auquel cas cette information doit \u00eatre recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer ou \u00e0 analyser correctement ou totalement. Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"error_num_voie_manquant()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.error_urgence_manquante","text":"Signale les arr\u00eat\u00e9s dont l'urgence n'a pu \u00eatre d\u00e9termin\u00e9e. La cause la plus fr\u00e9quente est une classe d'arr\u00eat\u00e9 qui ne donne pas explicitement cette information. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"error_urgence_manquante()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.error_ville_manquante","text":"Signale les adresses d'arr\u00eat\u00e9s sans ville. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: certaines mainlev\u00e9es ou abrogations), ou pas d'adresse incluant la ville, auquel cas la ville est d\u00e9termin\u00e9e selon d'autres indices (ex: lieu de signature), sinon recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer ou \u00e0 analyser correctement. Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"error_ville_manquante()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.error_voie_manquante","text":"Signale les adresses d'arr\u00eat\u00e9s sans voie. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: certaines mainlev\u00e9es ou abrogations), auquel cas cette information doit \u00eatre recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer ou \u00e0 analyser correctement. Ignore les valeurs manquantes. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"error_voie_manquante()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.examine_doc_content","text":"V\u00e9rifie des hypoth\u00e8ses de bonne formation sur le contenu extrait du document. Parameters: doc_content ( list [ dict ] ) \u2013 Empans de contenu extraits du document","title":"examine_doc_content()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.expect_footer_end_len","text":"V\u00e9rifie que les en-t\u00eates commencent tous \u00e0 0. Ignore les valeurs manquantes (aucun en-t\u00eate d\u00e9tect\u00e9). Parameters: df ( DataFrame ) \u2013 DataFrame contenant les zones rep\u00e9r\u00e9es dans les documents. Returns: success ( bool ) \u2013 True si tous les en-t\u00eates d\u00e9tect\u00e9s commencent \u00e0 0.","title":"expect_footer_end_len()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.expect_header_beg_zero","text":"V\u00e9rifie que les en-t\u00eates commencent tous \u00e0 0. Ignore les valeurs manquantes (aucun en-t\u00eate d\u00e9tect\u00e9). Parameters: df ( DataFrame ) \u2013 DataFrame contenant les zones rep\u00e9r\u00e9es dans les documents. Returns: success ( bool ) \u2013 True si tous les en-t\u00eates d\u00e9tect\u00e9s commencent \u00e0 0.","title":"expect_header_beg_zero()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.generate_html_report","text":"G\u00e9n\u00e9rer un rapport d'erreurs en HTML Parameters: run ( str ) \u2013 Identifiant de l'ex\u00e9cution df_adr ( DataFrame ) \u2013 Adresses df_arr ( DataFrame ) \u2013 Arr\u00eat\u00e9s df_not ( DataFrame ) \u2013 Notifi\u00e9s df_par ( DataFrame ) \u2013 Parcelles Returns: html_report ( string ) \u2013 Rapport HTML","title":"generate_html_report()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.warn_adresse_empty","text":"Signale les arr\u00eat\u00e9s sans aucune adresse. Certains arr\u00eat\u00e9s ne contiennent pas d'adresse (ex: mainlev\u00e9e, abrogation), auquel cas cette information doit \u00eatre recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs adresses que les scripts \u00e9chouent \u00e0 rep\u00e9rer. Ignore les valeurs manquantes. C'est une erreur pour l'utilisateur final mais un warning du point de vue du script, car la probabilit\u00e9 que l'adresse ne soit pas dans l'arr\u00eat\u00e9, sachant qu'aucune adresse n'a \u00e9t\u00e9 extraite, est relativement \u00e9lev\u00e9e. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"warn_adresse_empty()"},{"location":"Code%20Source/quality/#src.quality.validate_parses.warn_par_ref_cad_empty","text":"Signale les arr\u00eat\u00e9s sans aucune r\u00e9f\u00e9rence de parcelle cadastrale. Certains arr\u00eat\u00e9s ne contiennent pas de r\u00e9f\u00e9rence cadastrale, auquel cas cette information doit \u00eatre recherch\u00e9e puis renseign\u00e9e manuellement. D'autres arr\u00eat\u00e9s contiennent une ou plusieurs r\u00e9f\u00e9rences cadastrales que les scripts \u00e9chouent \u00e0 rep\u00e9rer. Ignore les valeurs manquantes. C'est une erreur pour l'utilisateur final mais un warning du point de vue du script, car la probabilit\u00e9 que la r\u00e9f\u00e9rence ne soit pas dans l'arr\u00eat\u00e9, sachant qu'aucune r\u00e9f\u00e9rence n'a \u00e9t\u00e9 extraite, est \u00e9lev\u00e9e. Parameters: df ( DataFrame ) \u2013 DataFrame contenant les arr\u00eat\u00e9s. Returns: df ( DataFrame ) \u2013 DataFrame contenant avec une colonne indiquant si cette erreur est pr\u00e9sente.","title":"warn_par_ref_cad_empty()"},{"location":"Code%20Source/utils/","text":"Utils Diverses fonctions utilitaires. Fonctions utiles pour la gestion des fichiers get_file_digest ( fp_pdf , digest = 'blake2b' , digest_size = 10 ) Extraire le hachage d'un fichier avec la fonction digest . Fonctionne pour Python >= 3.8, mais le code pourra \u00eatre simplifi\u00e9 pour Python >= 3.11 quand ce sera la version minimale requise par les principaux projets. Parameters: fp_pdf ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. digest ( str , default: 'blake2b' ) \u2013 Nom de la fonction de hachage \u00e0 utiliser, \"sha1\" par d\u00e9faut. digest_size ( int , default: 10 ) \u2013 Taille du digest (blake2b, sinon ignor\u00e9). Returns: fd_hexdigest ( str ) \u2013 Hachage du fichier. Reconnaissance et mise en forme des dates process_date_brute ( arr_date ) Extraire les diff\u00e9rents champs d'une date brute et la normaliser. Parameters: arr_date ( str ) \u2013 Date brute Returns: arr_date_norm ( str ) \u2013 Date normalis\u00e9e dd/mm/yyyy Fonctions utilitaires g\u00e9n\u00e9riques pour le texte create_file_name_url ( file_name , allowance = 155 ) Creates a URL-compliant filename by removing non-alphanumeric characters, accentuated letters, and maintaining the Windows path length limit. Parameters: file_name ( str ) \u2013 Nom du fichier allowance ( int , default: 155 ) \u2013 Longueur maximale du chemin complet (chemin + nom de fichier) normalize_string ( raw_str , num = False , apos = False , hyph = False , spaces = False ) Normaliser une cha\u00eene de caract\u00e8res. Remplacer les s\u00e9quences d'espaces par une unique espace. Parameters: raw_str ( str ) \u2013 Cha\u00eene de caract\u00e8res \u00e0 normaliser Returns: nor_str ( str ) \u2013 Cha\u00eene de caract\u00e8res normalis\u00e9e remove_accents ( str_in ) Enl\u00e8ve les accents d'une cha\u00eene de caract\u00e8res. cf. https://stackoverflow.com/a/517974 Parameters: str_in ( str ) \u2013 Cha\u00eene de caract\u00e8res pouvant contenir des caract\u00e8res combinants (accents, c\u00e9dille etc.). Returns: str_out ( string ) \u2013 Cha\u00eene de caract\u00e8res sans caract\u00e8re combinant. Charger les fichiers de texte extraits des PDF, natifs ou non load_pages_text ( fp_txt , page_break = ' \\x0c ' ) Charge le texte d'un document, d\u00e9coup\u00e9 en pages. Parameters: fp_txt ( Path ) \u2013 Chemin du fichier contenant le texte d'un document. page_break ( str , default: '\\x0c' ) \u2013 S\u00e9parateur de pages. Les fichiers PDF texte produits par l'export direct depuis les logiciels de traitement de texte contiennent d\u00e9j\u00e0 un \"form feed\" (\" \"), comme les fichiers \"sidecar\" produits par ocrmypdf (pour les fichiers PDF image). Returns: doc_txt ( List [ str ] ) \u2013 Texte du document, par page.","title":"Utils"},{"location":"Code%20Source/utils/#utils","text":"Diverses fonctions utilitaires.","title":"Utils"},{"location":"Code%20Source/utils/#fonctions-utiles-pour-la-gestion-des-fichiers","text":"","title":"Fonctions utiles pour la gestion des fichiers"},{"location":"Code%20Source/utils/#src.utils.file_utils.get_file_digest","text":"Extraire le hachage d'un fichier avec la fonction digest . Fonctionne pour Python >= 3.8, mais le code pourra \u00eatre simplifi\u00e9 pour Python >= 3.11 quand ce sera la version minimale requise par les principaux projets. Parameters: fp_pdf ( Path ) \u2013 Chemin du fichier PDF \u00e0 traiter. digest ( str , default: 'blake2b' ) \u2013 Nom de la fonction de hachage \u00e0 utiliser, \"sha1\" par d\u00e9faut. digest_size ( int , default: 10 ) \u2013 Taille du digest (blake2b, sinon ignor\u00e9). Returns: fd_hexdigest ( str ) \u2013 Hachage du fichier.","title":"get_file_digest()"},{"location":"Code%20Source/utils/#reconnaissance-et-mise-en-forme-des-dates","text":"","title":"Reconnaissance et mise en forme des dates"},{"location":"Code%20Source/utils/#src.utils.str_date.process_date_brute","text":"Extraire les diff\u00e9rents champs d'une date brute et la normaliser. Parameters: arr_date ( str ) \u2013 Date brute Returns: arr_date_norm ( str ) \u2013 Date normalis\u00e9e dd/mm/yyyy","title":"process_date_brute()"},{"location":"Code%20Source/utils/#fonctions-utilitaires-generiques-pour-le-texte","text":"","title":"Fonctions utilitaires g\u00e9n\u00e9riques pour le texte"},{"location":"Code%20Source/utils/#src.utils.text_utils.create_file_name_url","text":"Creates a URL-compliant filename by removing non-alphanumeric characters, accentuated letters, and maintaining the Windows path length limit. Parameters: file_name ( str ) \u2013 Nom du fichier allowance ( int , default: 155 ) \u2013 Longueur maximale du chemin complet (chemin + nom de fichier)","title":"create_file_name_url()"},{"location":"Code%20Source/utils/#src.utils.text_utils.normalize_string","text":"Normaliser une cha\u00eene de caract\u00e8res. Remplacer les s\u00e9quences d'espaces par une unique espace. Parameters: raw_str ( str ) \u2013 Cha\u00eene de caract\u00e8res \u00e0 normaliser Returns: nor_str ( str ) \u2013 Cha\u00eene de caract\u00e8res normalis\u00e9e","title":"normalize_string()"},{"location":"Code%20Source/utils/#src.utils.text_utils.remove_accents","text":"Enl\u00e8ve les accents d'une cha\u00eene de caract\u00e8res. cf. https://stackoverflow.com/a/517974 Parameters: str_in ( str ) \u2013 Cha\u00eene de caract\u00e8res pouvant contenir des caract\u00e8res combinants (accents, c\u00e9dille etc.). Returns: str_out ( string ) \u2013 Cha\u00eene de caract\u00e8res sans caract\u00e8re combinant.","title":"remove_accents()"},{"location":"Code%20Source/utils/#charger-les-fichiers-de-texte-extraits-des-pdf-natifs-ou-non","text":"","title":"Charger les fichiers de texte extraits des PDF, natifs ou non"},{"location":"Code%20Source/utils/#src.utils.txt_format.load_pages_text","text":"Charge le texte d'un document, d\u00e9coup\u00e9 en pages. Parameters: fp_txt ( Path ) \u2013 Chemin du fichier contenant le texte d'un document. page_break ( str , default: '\\x0c' ) \u2013 S\u00e9parateur de pages. Les fichiers PDF texte produits par l'export direct depuis les logiciels de traitement de texte contiennent d\u00e9j\u00e0 un \"form feed\" (\" \"), comme les fichiers \"sidecar\" produits par ocrmypdf (pour les fichiers PDF image). Returns: doc_txt ( List [ str ] ) \u2013 Texte du document, par page.","title":"load_pages_text()"},{"location":"Notebooks/notebooks/","text":"Notebooks Des notebooks pour explorer les donn\u00e9es et les r\u00e9sultats. explore_actes.ipynb Ce notebook explore les donn\u00e9es des arr\u00eat\u00e9s de p\u00e9rils et les r\u00e9sultats de leur traitement. test_pds_image.ipynb Un test d'extraction du texte d'arr\u00eat\u00e9s de p\u00e9rils (PDF texte et image).","title":"Notebooks"},{"location":"Notebooks/notebooks/#notebooks","text":"Des notebooks pour explorer les donn\u00e9es et les r\u00e9sultats. explore_actes.ipynb Ce notebook explore les donn\u00e9es des arr\u00eat\u00e9s de p\u00e9rils et les r\u00e9sultats de leur traitement. test_pds_image.ipynb Un test d'extraction du texte d'arr\u00eat\u00e9s de p\u00e9rils (PDF texte et image).","title":"Notebooks"},{"location":"Scripts/scripts/","text":"Scripts Le dossier scripts contient des scripts shell pour automatiser certaines t\u00e2ches. Chacun de ces scripts contient des param\u00e8tres d'entr\u00e9e \u00e0 configurer en d\u00e9but de fichier. Le script principal permettant de lancer tout les traitements : process.sh Plusieurs scripts pour faciliter le nettoyage des donn\u00e9es en cas de probl\u00e8me ou pendant les d\u00e9veloppements : cleanall.sh : supprime les fichiers sources et les fichiers g\u00e9n\u00e9r\u00e9s par les scripts. cleanbest.sh : supprime les fichiers temporaires et les fichiers g\u00e9n\u00e9r\u00e9s par les scripts. cleanfast.sh : supprime uniquement les fichiers temporaires pouvant bloquer les prochains lancements de scripts. cleanpreprocess.sh : supprime les fichiers temporaraires. Des scripts pour lancer les scripts de pr\u00e9traitement des donn\u00e9es : parsebest.sh : lance les scripts de pr\u00e9traitements des donn\u00e9es avec les param\u00e8tres aux meilleures performances. parsefast.sh : lance les scripts de pr\u00e9traitements des donn\u00e9es avec les param\u00e8tres les plus rapides.","title":"Scripts"},{"location":"Scripts/scripts/#scripts","text":"Le dossier scripts contient des scripts shell pour automatiser certaines t\u00e2ches. Chacun de ces scripts contient des param\u00e8tres d'entr\u00e9e \u00e0 configurer en d\u00e9but de fichier. Le script principal permettant de lancer tout les traitements : process.sh Plusieurs scripts pour faciliter le nettoyage des donn\u00e9es en cas de probl\u00e8me ou pendant les d\u00e9veloppements : cleanall.sh : supprime les fichiers sources et les fichiers g\u00e9n\u00e9r\u00e9s par les scripts. cleanbest.sh : supprime les fichiers temporaires et les fichiers g\u00e9n\u00e9r\u00e9s par les scripts. cleanfast.sh : supprime uniquement les fichiers temporaires pouvant bloquer les prochains lancements de scripts. cleanpreprocess.sh : supprime les fichiers temporaraires. Des scripts pour lancer les scripts de pr\u00e9traitement des donn\u00e9es : parsebest.sh : lance les scripts de pr\u00e9traitements des donn\u00e9es avec les param\u00e8tres aux meilleures performances. parsefast.sh : lance les scripts de pr\u00e9traitements des donn\u00e9es avec les param\u00e8tres les plus rapides.","title":"Scripts"}]}